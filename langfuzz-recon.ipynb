{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "urllib3 already exists, skipping download.\n",
      "requests already exists, skipping download.\n",
      "aiohttp already exists, skipping download.\n",
      "twisted already exists, skipping download.\n",
      "oss-fuzz already exists, skipping download.\n",
      "twisted Repo does not exist\n",
      "Library urllib3 already exists, skipping.\n",
      "Library requests already exists, skipping.\n",
      "Library aiohttp already exists, skipping.\n",
      "Library twisted already exists, skipping.\n",
      "File fuzz_requests.py already exists for library urllib3, skipping.\n",
      "File fuzz_urlparse.py already exists for library urllib3, skipping.\n",
      "File fuzz_server.py already exists for library requests, skipping.\n",
      "File fuzz_web_request.py already exists for library aiohttp, skipping.\n",
      "File fuzz_payload_url.py already exists for library aiohttp, skipping.\n",
      "File fuzz_http_parser.py already exists for library aiohttp, skipping.\n",
      "File fuzz_multipart.py already exists for library aiohttp, skipping.\n",
      "File fuzz_http_payload_parser.py already exists for library aiohttp, skipping.\n"
     ]
    }
   ],
   "source": [
    "# Extract github value from dictionary and download git repo to directory named after the dictionary\n",
    "import os\n",
    "import git\n",
    "\n",
    "from langfuzzDB import Library, LibraryFile, create_tables, get_engine\n",
    "from sqlalchemy.orm import Session\n",
    "\n",
    "http_libs = {\n",
    " 'urllib3': {\n",
    " 'github': 'https://github.com/urllib3/urllib3',\n",
    " 'docs': 'https://urllib3.readthedocs.io/en/stable/'\n",
    "},\n",
    " 'requests': {\n",
    " 'github': 'https://github.com/psf/requests',\n",
    " 'docs': 'https://requests.readthedocs.io/en/latest/'\n",
    " },\n",
    "'aiohttp': {\n",
    " 'github': 'https://github.com/aio-libs/aiohttp/',\n",
    " 'docs': 'https://docs.aiohttp.org/en/stable/'\n",
    " },\n",
    " 'twisted': {\n",
    " 'github': 'https://github.com/twisted/twisted',\n",
    " 'docs': 'https://docs.twisted.org/en/stable/'\n",
    " }\n",
    "}\n",
    "\n",
    "utils = {\n",
    " 'oss-fuzz': {\n",
    "\t 'github': 'https://github.com/google/oss-fuzz'\n",
    "\t }\n",
    " }\n",
    "\n",
    "def download_github_repos(lib_dicts, repo_path):\n",
    "    for lib_dict in lib_dicts:\n",
    "        \n",
    "      for lib_name, lib_data in lib_dict.items():\n",
    "            repo_dir = os.path.join(repo_path, lib_name)\n",
    "            if not os.path.exists(repo_dir):\n",
    "                git_url = lib_data[\"github\"]\n",
    "                print(f\"Cloning {lib_name} from {git_url}...\")\n",
    "                git.Repo.clone_from(git_url, repo_dir)\n",
    "            else:\n",
    "                print(f\"{lib_name} already exists, skipping download.\")\n",
    "\n",
    "# iterate http_libs dictionary and find all python fuzz files\n",
    "# path = repo_path + http_libs[key]\n",
    "# fuzz files start with \"fuzz\" and end with \".py\"\n",
    "# save the fuzz files to a dictionary with the key being the library name and the value being the path to the fuzz file\n",
    "def get_fuzz_files(lib_dict, repo_path):\n",
    "    fuzz_files = {}\n",
    "    for key in lib_dict:\n",
    "        path = repo_path + '/oss-fuzz/projects/' + str(key)\n",
    "        fuzz_files[str(key)] = []\n",
    "        # if the path exists, find all fuzz files\n",
    "        if os.path.exists(path):\n",
    "            for root, dirs, files in os.walk(path):\n",
    "                for file in files:\n",
    "                    if file.startswith(\"fuzz\") and file.endswith(\".py\"):\n",
    "                        fuzz_files[key].append(os.path.join(root, file))\n",
    "        else:\n",
    "            print(f\"{key} Repo does not exist\")\n",
    "    return(fuzz_files)\n",
    "\n",
    "# save library info to sqlite database\n",
    "def save_libs(libs, sqlitedb, lang):\n",
    "    engine = get_engine(sqlitedb)\n",
    "    create_tables(engine)\n",
    "    session = Session(engine)\n",
    "\n",
    "    for library_name, lib_data in libs.items():\n",
    "        github_url = lib_data['github']\n",
    "        docs_url = lib_data['docs']\n",
    "        language = lang\n",
    "\n",
    "        existing_lib = session.query(Library).filter_by(library_name=library_name).first()\n",
    "        if existing_lib is None:\n",
    "            lib = Library(library_name=library_name, github_url=github_url, docs_url=docs_url, language=language)\n",
    "            session.add(lib)\n",
    "        else:\n",
    "            print(f\"Library {library_name} already exists, skipping.\")\n",
    "\n",
    "    session.commit()\n",
    "    session.close()\n",
    "\n",
    "# save fuzz files to sqlite database\n",
    "def save_fuzz_files(fuzz_files, sqlitedb, lang):\n",
    "    engine = get_engine(sqlitedb)\n",
    "    create_tables(engine)\n",
    "    session = Session(engine)\n",
    "\n",
    "    for library_name, file_list in fuzz_files.items():\n",
    "        for file_path in file_list:\n",
    "            file_name = os.path.basename(file_path)\n",
    "            with open(file_path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "            first_source_line_index = next((index for index, line in enumerate(lines) if line.startswith(\"import\")), 0)\n",
    "            contents = \"\".join(lines[first_source_line_index:])\n",
    "\n",
    "            existing_file = session.query(LibraryFile).filter_by(library_name=library_name, file_name=file_name).first()\n",
    "            if existing_file is None:\n",
    "                lib_file = LibraryFile(library_name=library_name, file_name=file_name, contents=contents, generated=False, fuzz_test=True, type=\"fuzzer\")\n",
    "                session.add(lib_file)\n",
    "            else:\n",
    "                print(f\"File {file_name} already exists for library {library_name}, skipping.\")\n",
    "\n",
    "    session.commit()\n",
    "    session.close()\n",
    "\n",
    "\n",
    "def save_recon_data(libs, fuzz_files, sqlitedb, lang):\n",
    "    save_libs(libs, sqlitedb, lang)\n",
    "    save_fuzz_files(fuzz_files, sqlitedb, lang)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Set up\n",
    "repo_path = \"github_repos\"\n",
    "os.makedirs(repo_path) if not os.path.exists(repo_path) else None\n",
    "sqlitedb = \"langfuzz.db\"\n",
    "libs = [http_libs, utils]\n",
    "\n",
    "# Download repos from http_libs and utils dictionaries\n",
    "download_github_repos(libs, repo_path)\n",
    "# get fuzzed files from oss-fuzz repo\n",
    "fuzz_files = get_fuzz_files(http_libs, repo_path)\n",
    "# save fuzzed files and library info in sqlite database\n",
    "save_recon_data(http_libs, fuzz_files, sqlitedb, 'python')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "github_repos/oss-fuzz/projects/urllib3\n",
      "github_repos/oss-fuzz/projects/requests\n",
      "github_repos/oss-fuzz/projects/aiohttp\n",
      "github_repos/oss-fuzz/projects/twisted\n",
      "twisted Repo does not exist\n",
      "{'urllib3': ['github_repos/oss-fuzz/projects/urllib3/fuzz_requests.py', 'github_repos/oss-fuzz/projects/urllib3/fuzz_urlparse.py'], 'requests': ['github_repos/oss-fuzz/projects/requests/fuzz_server.py'], 'aiohttp': ['github_repos/oss-fuzz/projects/aiohttp/fuzz_web_request.py', 'github_repos/oss-fuzz/projects/aiohttp/fuzz_payload_url.py', 'github_repos/oss-fuzz/projects/aiohttp/fuzz_http_parser.py', 'github_repos/oss-fuzz/projects/aiohttp/fuzz_multipart.py', 'github_repos/oss-fuzz/projects/aiohttp/fuzz_http_payload_parser.py'], 'twisted': []}\n"
     ]
    }
   ],
   "source": [
    "def get_fuzz_files(repo_path, lib_dict):\n",
    "    fuzz_files = {}\n",
    "    for key in lib_dict:\n",
    "        path = repo_path + '/oss-fuzz/projects/' + key\n",
    "        fuzz_files[key] = []\n",
    "        print(path)\n",
    "        # if the path exists, find all fuzz files\n",
    "        if os.path.exists(path):\n",
    "            for root, dirs, files in os.walk(path):\n",
    "                for file in files:\n",
    "                    if file.startswith(\"fuzz\") and file.endswith(\".py\"):\n",
    "                        fuzz_files[key].append(os.path.join(root, file))\n",
    "        else:\n",
    "            print(f\"{key} Repo does not exist\")\n",
    "    return(fuzz_files)\n",
    "\n",
    "\n",
    "repo_path = \"github_repos\"\n",
    "# fuzz_files are library names and the path to the fuzz file\n",
    "# fuzz_files['aiohttp'] = [file1, file2, file3]\n",
    "fuzz_files = get_fuzz_files(repo_path, http_libs)\n",
    "\n",
    "# prompt = base_prompt + docs + fuzz_tests + special_cases\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all functions and source code from a library\n",
    "import inspect\n",
    "import importlib\n",
    "import pkgutil\n",
    "import sys\n",
    "\n",
    "def get_functions_from_library(library_name):\n",
    "    funcs = {}\n",
    "    library = importlib.import_module(library_name)\n",
    "\n",
    "    # Iterate through all the modules within the library\n",
    "    for _, name, is_pkg in pkgutil.walk_packages(library.__path__):\n",
    "        if is_pkg:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            module = importlib.import_module(f\"{library_name}.{name}\")\n",
    "\n",
    "            for func_name, obj in inspect.getmembers(module):\n",
    "                if inspect.isfunction(obj):\n",
    "                    funcs.update({func_name: inspect.getsource(obj)})\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading module {name}: {e}\")\n",
    "\n",
    "    return funcs\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    library_name = \"urllib3\"  # Replace this with the library you want to analyze\n",
    "    functions = get_functions_from_library(library_name)\n",
    "\n",
    "    # Print function names and their source code\n",
    "    for func_name, source_code in functions.items():\n",
    "        print(f\"Function Name: {func_name}\")\n",
    "        print(\"Source Code:\")\n",
    "        print(source_code)\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "priority_funcs = 'create_urllib3_context', 'ssl_wrap_socket','match_hostname', 'parse_url'\n",
    "# find priority functions from functions first, then move on to other functions\n",
    "# if priority functions are not found, then move on to other functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and parse radon CC metrics to create list of priority functions\n",
    "data = \"\"\"\n",
    "    F 95:0 _default_key_normalizer - B\n",
    "    F 623:0 proxy_from_url - A\n",
    "    F 43:0 ensure_can_construct_http_header_dict - B\n",
    "    F 701:0 _ssl_wrap_socket_and_match_hostname - D\n",
    "    F 845:0 _wrap_proxy_error - A\n",
    "    F 819:0 _match_hostname - A\n",
    "    F 884:0 _url_from_connection - A\n",
    "    F 869:0 _get_default_user_agent - A\n",
    "    F 1106:0 connection_from_url - A\n",
    "    F 1145:0 _normalize_host - A\n",
    "    F 1170:0 _close_pool_connections - A\n",
    "    F 1136:0 _normalize_host - A\n",
    "    F 1141:0 _normalize_host - A\n",
    "    F 1163:0 _url_from_pool - A\n",
    "    F 202:0 _get_decoder - B\n",
    "    F 87:0 add_stderr_logger - A\n",
    "    F 120:0 disable_warnings - A\n",
    "    F 130:0 request - A\n",
    "    F 51:0 encode_multipart_formdata - A\n",
    "    F 29:0 iter_field_objects - A\n",
    "    F 22:0 choose_boundary - A\n",
    "    F 31:0 format_header_param_rfc2231 - B\n",
    "    F 15:0 guess_content_type - A\n",
    "    F 79:0 format_multipart_header_param - A\n",
    "    F 117:0 format_header_param_html5 - A\n",
    "    F 135:0 format_header_param - A\n",
    "    F 193:0 _read_callback - C\n",
    "    F 250:0 _write_callback - C\n",
    "    F 173:0 inject_into_urllib3 - A\n",
    "    F 183:0 extract_from_urllib3 - A\n",
    "    F 729:0 makefile - A\n",
    "    F 235:0 get_subj_alt_name - B\n",
    "    F 168:0 _validate_dependencies_met - A\n",
    "    F 194:0 _dnsname_to_stdlib - A\n",
    "    F 148:0 inject_into_urllib3 - A\n",
    "    F 159:0 extract_from_urllib3 - A\n",
    "    F 549:0 _verify_callback - A\n",
    "    F 168:0 _cert_array_from_pem - B\n",
    "    F 322:0 _load_client_cert_chain - B\n",
    "    F 89:0 _create_cfstring_array - B\n",
    "    F 145:0 _assert_no_error - A\n",
    "    F 265:0 _load_items_from_file - A\n",
    "    F 120:0 _cf_string_to_unicode - A\n",
    "    F 51:0 _cf_dictionary_from_tuples - A\n",
    "    F 41:0 _cf_data_from_bytes - A\n",
    "    F 75:0 _cfstr - A\n",
    "    F 214:0 _is_cert - A\n",
    "    F 222:0 _is_identity - A\n",
    "    F 230:0 _temporary_keychain - A\n",
    "    F 406:0 _build_tls_unknown_ca_alert - A\n",
    "    F 65:0 load_cdll - A\n",
    "    F 33:0 select_wait_for_socket - B\n",
    "    F 57:0 poll_wait_for_socket - A\n",
    "    F 82:0 _have_working_poll - A\n",
    "    F 95:0 wait_for_socket - A\n",
    "    F 113:0 wait_for_read - A\n",
    "    F 120:0 wait_for_write - A\n",
    "    F 27:0 create_connection - B\n",
    "    F 114:0 _has_ipv6 - A\n",
    "    F 93:0 _set_socket_options - A\n",
    "    F 103:0 allowed_gai_family - A\n",
    "    F 15:0 is_connection_dropped - A\n",
    "    F 55:0 make_headers - B\n",
    "    F 189:0 body_to_chunks - B\n",
    "    F 154:0 rewind_body - A\n",
    "    F 134:0 set_file_position - A\n",
    "    F 11:0 connection_requires_http_tunnel - B\n",
    "    F 40:0 assert_header_parsing - B\n",
    "    F 9:0 is_fp_closed - A\n",
    "    F 91:0 is_response_to_head - A\n",
    "    F 7:0 to_bytes - B\n",
    "    F 19:0 to_str - B\n",
    "    F 31:0 reraise - A\n",
    "    F 369:0 parse_url - D\n",
    "    F 263:0 _remove_path_dot_segments - B\n",
    "    F 303:0 _normalize_host - B\n",
    "    F 227:0 _encode_invalid_chars - B\n",
    "    F 332:0 _idna_encode - A\n",
    "    F 351:0 _encode_target - A\n",
    "    F 214:0 _encode_invalid_chars - A\n",
    "    F 221:0 _encode_invalid_chars - A\n",
    "    F 294:0 _normalize_host - A\n",
    "    F 299:0 _normalize_host - A\n",
    "    F 208:0 create_urllib3_context - C\n",
    "    F 388:0 ssl_wrap_socket - C\n",
    "    F 28:0 _is_bpo_43522_fixed - B\n",
    "    F 139:0 assert_fingerprint - A\n",
    "    F 169:0 resolve_cert_reqs - A\n",
    "    F 192:0 resolve_ssl_version - A\n",
    "    F 463:0 is_ipaddress - A\n",
    "    F 476:0 _is_key_file_encrypted - A\n",
    "    F 487:0 _ssl_wrap_socket_impl - A\n",
    "    F 57:0 _is_has_never_check_common_name_reliable - A\n",
    "    F 351:0 ssl_wrap_socket - A\n",
    "    F 370:0 ssl_wrap_socket - A\n",
    "    F 95:0 match_hostname - C\n",
    "    F 24:0 _dnsname_match - B\n",
    "    F 80:0 _ipaddress_match - A\n",
    "\"\"\"\n",
    "\n",
    "def parse_function_data(data):\n",
    "    functions = []\n",
    "\n",
    "    for line in data.strip().split('\\n'):\n",
    "        parts = line.split()\n",
    "        function_name = parts[2]\n",
    "\n",
    "        if not function_name.startswith('_'):\n",
    "            score = parts[-1]\n",
    "            functions.append((function_name, score))\n",
    "\n",
    "    return functions\n",
    "\n",
    "def arrange_by_score(functions):\n",
    "    return sorted(functions, key=lambda x: x[1])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # radon cc src/ | grep -E '^\\s*F\\s+' > functions.txt\n",
    "    functions = parse_function_data(data)\n",
    "    arranged_functions = arrange_by_score(functions)\n",
    "\n",
    "    for function_name, score in arranged_functions:\n",
    "        # if score is not 'A' or 'B'\n",
    "        if score not in ('A', 'B'):\n",
    "            print(f\"{function_name} - {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to sqlite DB\n",
    "# sqlalchemy\n",
    "# prompt = base_prompt + docs + fuzz_tests\n",
    "import sqlalchemy\n",
    "\n",
    "# create engine\n",
    "engine = sqlalchemy.create_engine('sqlite:///langfuzz.db')\n",
    "\n",
    "#create table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path: github_repos/aiohttp/aiohttp/web_exceptions.py\n",
      "Function: F 497:0 _initialize_default_reason - B\n",
      "\n",
      "Path: github_repos/aiohttp/aiohttp/helpers.py\n",
      "Function: F 387:0 content_disposition_header - C\n",
      "\n",
      "Path: github_repos/aiohttp/aiohttp/helpers.py\n",
      "Function: F 275:0 proxies_from_env - B\n",
      "\n",
      "Path: github_repos/aiohttp/aiohttp/helpers.py\n",
      "Function: F 198:0 netrc_from_env - B\n",
      "\n",
      "Path: github_repos/aiohttp/aiohttp/helpers.py\n",
      "Function: F 246:0 basicauth_from_netrc - B\n",
      "\n",
      "Path: github_repos/aiohttp/aiohttp/pytest_plugin.py\n",
      "Function: F 196:0 pytest_generate_tests - B\n",
      "\n",
      "Path: github_repos/aiohttp/aiohttp/pytest_plugin.py\n",
      "Function: F 126:0 _runtime_warning_context - B\n",
      "\n",
      "Path: github_repos/aiohttp/aiohttp/multipart.py\n",
      "Function: F 74:0 parse_content_disposition - C\n",
      "\n",
      "Path: github_repos/aiohttp/aiohttp/multipart.py\n",
      "Function: F 173:0 content_disposition_filename - C\n",
      "\n",
      "Path: github_repos/aiohttp/aiohttp/http_websocket.py\n",
      "Function: F 172:0 ws_ext_parse - C\n",
      "\n",
      "Path: github_repos/aiohttp/aiohttp/http_websocket.py\n",
      "Function: F 223:0 ws_ext_gen - B\n",
      "\n",
      "Path: github_repos/aiohttp/aiohttp/web.py\n",
      "Function: F 272:0 _run_app - C\n",
      "\n",
      "Path: github_repos/aiohttp/aiohttp/web.py\n",
      "Function: F 447:0 run_app - B\n",
      "\n",
      "Path: github_repos/aiohttp/aiohttp/web.py\n",
      "Function: F 516:0 main - B\n",
      "\n",
      "Path: github_repos/aiohttp/aiohttp/web.py\n",
      "Function: F 423:0 _cancel_tasks - B\n",
      "\n",
      "Path: github_repos/aiohttp/aiohttp/test_utils.py\n",
      "Function: F 560:0 make_mocked_request - C\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = \"aiohttp_cc.txt\"\n",
    "\n",
    "def extract_functions_from_output(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        output = file.read()\n",
    "\n",
    "    lines = output.splitlines()\n",
    "\n",
    "    extracted_data = []\n",
    "    current_path = \"\"\n",
    "\n",
    "    for line in lines:\n",
    "        stripped_line = line.strip()\n",
    "\n",
    "        if stripped_line.startswith(\"github_repos\"):\n",
    "            current_path = stripped_line\n",
    "        elif stripped_line.startswith(\"F\"):\n",
    "            extracted_data.append((current_path, stripped_line))\n",
    "\n",
    "    return extracted_data\n",
    "\n",
    "extracted_data = extract_functions_from_output(file_path)\n",
    "\n",
    "# Print the extracted data\n",
    "for path, function in extracted_data:\n",
    "    print(f\"Path: {path}\\nFunction: {function}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "libs = {\n",
    "    'sqlalchemy': 'https://github.com/sqlalchemy/sqlalchemy',\n",
    "    'pillow': 'https://github.com/python-pillow/Pillow',\n",
    "    'babel': 'https://github.com/python-babel/babel',\n",
    "    'pyyaml': 'https://github.com/yaml/pyyaml',\n",
    "    'cryptography': {\n",
    "        'github': 'https://github.com/pyca/cryptography',\n",
    "        'docs': 'https://cryptography.io/en/latest/'\n",
    "    }\n",
    "}\n",
    "\n",
    "libs2 = {\n",
    "    'botocore': 'https://github.com/boto/botocore',\n",
    "    'boto3': 'https://github.com/boto/boto3',\n",
    "    'rq': 'https://github.com/rq/rq',\n",
    "    'pip': 'https://github.com/pypa/pip',\n",
    "    'grpc': {\n",
    "        'github': 'https://github.com/grpc/grpc',\n",
    "        'docs': 'https://grpc.github.io/grpc/python/'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Help me write the save_libs() and save_fuzz_files() functions to store data into a sqlite database. This is the outline:\n",
    "\n",
    "def save_recon_data(libs, fuzz_files, sqlitedb, lang):\n",
    "    save_libs(libs, sqlitedb, lang)\n",
    "    save_fuzz_files(fuzz_files, sqlitedb, lang)\n",
    "\n",
    "example input:\n",
    "\n",
    "fuzz_files={'urllib3': ['github_repos/oss-fuzz/projects/urllib3/fuzz_requests.py', 'github_repos/oss-fuzz/projects/urllib3/fuzz_urlparse.py'], 'requests': ['github_repos/oss-fuzz/projects/requests/fuzz_server.py'], 'aiohttp': ['github_repos/oss-fuzz/projects/aiohttp/fuzz_web_request.py', 'github_repos/oss-fuzz/projects/aiohttp/fuzz_payload_url.py', 'github_repos/oss-fuzz/projects/aiohttp/fuzz_http_parser.py', 'github_repos/oss-fuzz/projects/aiohttp/fuzz_multipart.py', 'github_repos/oss-fuzz/projects/aiohttp/fuzz_http_payload_parser.py'], 'twisted': []}\n",
    "\n",
    "http_libs = {\n",
    " 'urllib3': {\n",
    " 'github': 'https://github.com/urllib3/urllib3',\n",
    " 'docs': 'https://urllib3.readthedocs.io/en/stable/'\n",
    "},\n",
    " 'requests': {\n",
    " 'github': 'https://github.com/psf/requests',\n",
    " 'docs': 'https://requests.readthedocs.io/en/latest/'\n",
    " },\n",
    "'aiohttp': {\n",
    " 'github': 'https://github.com/aio-libs/aiohttp/',\n",
    " 'docs': 'https://docs.aiohttp.org/en/stable/'\n",
    " },\n",
    " 'twisted': {\n",
    " 'github': 'https://github.com/twisted/twisted',\n",
    " 'docs': 'https://docs.twisted.org/en/stable/'\n",
    " }\n",
    "}\n",
    "\n",
    "sqlitedb = langfuzz.db\n",
    "lang = 'python'\n",
    "\n",
    "save_libs(libs, sqlitedb, lang) should save the following data into the sqlite database table named 'libraries':\n",
    "library_name = libs[key]\n",
    "github_url = libs[key]['github']\n",
    "docs_url = libs[key]['docs']\n",
    "language = lang\n",
    "\n",
    "save_fuzz_files(fuzz_files, sqlitedb, lang) should open the fuzz_files and save the following data into the sqlite database table named 'library_files':\n",
    "library_name = fuzz_files[key]\n",
    "file_name = text after last slash from fuzz_files[key][i]; for example fuzz_http_payload_parser.py from 'github_repos/oss-fuzz/projects/aiohttp/fuzz_http_payload_parser.py'\n",
    "contents = open(fuzz_files[key][i], 'r').read() and save file contents as a string starting from the line with 'import' and ending with the last line of the file\n",
    "generated: false\n",
    "fuzz_test: true\n",
    "type: fuzzer\n",
    "\n",
    "The sqlite database should have the following tables:\n",
    "libraries, and library_files\n",
    "\n",
    "Return code for the two functions and return a langfuzzDB.py file where we implement the sqlite database with sqlalchemy.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fuzzforest",
   "language": "python",
   "name": "fuzzforest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
