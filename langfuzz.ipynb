{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Bright Socks Inc.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(temperature=0.9)\n",
    "text = \"What would be a good company name for a company that makes colorful socks?\"\n",
    "print(llm(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "import atheris\n",
      "import sys\n",
      "from io import BytesIO\n",
      "import random\n",
      "import string\n",
      "import six\n",
      "\n",
      "def choose_boundary():\n",
      "    \"\"\"\n",
      "    Our implementation of choose_boundary function.\n",
      "    \"\"\"\n",
      "    return ''.join(random.choice(string.ascii_letters + string.digits) for _ in range(30))\n",
      "\n",
      "def iter_field_objects(fields):\n",
      "    \"\"\"\n",
      "    Our implementation of iter_field_objects function.\n",
      "    \"\"\"\n",
      "    if isinstance(fields, dict):\n",
      "        fields = list(fields.items())\n",
      "\n",
      "    for field in fields:\n",
      "        if isinstance(field, tuple):\n",
      "            yield RequestField(*field)\n",
      "        else:\n",
      "            yield field\n",
      "\n",
      "def b(data):\n",
      "    \"\"\"\n",
      "    Our implementation of b function.\n",
      "    \"\"\"\n",
      "    if isinstance(data, six.text_type):\n",
      "        return data.encode('utf-8')\n",
      "    return data\n",
      "\n",
      "class RequestField(object):\n",
      "    \"\"\"\n",
      "    Our implementation of RequestField class.\n",
      "    \"\"\"\n",
      "    def __init__(self, name, data, filename=None, headers=None):\n",
      "        self.name = name\n",
      "        self.data = data\n",
      "        self.filename = filename\n",
      "        self.headers = headers or {}\n",
      "\n",
      "    def render_headers(self):\n",
      "        \"\"\"\n",
      "        Our implementation of render_headers function.\n",
      "        \"\"\"\n",
      "        header_items = []\n",
      "\n",
      "        disposition = 'form-data; name=\"%s\"' % self.name\n",
      "        if self.filename:\n",
      "            disposition += '; filename=\"%s\"' % self.filename\n",
      "        header_items.append(('Content-Disposition', disposition))\n",
      "\n",
      "        content_type = self.headers.get('Content-Type', 'application/octet-stream')\n",
      "        header_items.append(('Content-Type', content_type))\n",
      "\n",
      "        return b('\\r\\n'.join('%s: %s' % (header, value) for header, value in header_items) + '\\r\\n\\r\\n')\n",
      "\n",
      "def TestOneInput(data):\n",
      "    fdp = atheris.FuzzedDataProvider(data)\n",
      "    fields = {}\n",
      "    for i in range(0, fdp.ConsumeIntInRange(0, 10)):\n",
      "        name = fdp.ConsumeString(sys.maxsize)\n",
      "        data = fdp.ConsumeString(sys.maxsize)\n",
      "        filename = None if fdp.ConsumeBool() else fdp.ConsumeString(sys.maxsize)\n",
      "        headers = None if fdp.ConsumeBool() else {fdp.ConsumeString(sys.maxsize): fdp.ConsumeString(sys.maxsize)}\n",
      "        fields[name] = RequestField(name, data, filename, headers)\n",
      "\n",
      "    boundary = None if fdp.ConsumeBool() else choose_boundary()\n",
      "\n",
      "    encode_multipart_formdata(fields, boundary)\n",
      "\n",
      "def main():\n",
      "    atheris.Setup(sys.argv, TestOneInput)\n",
      "    atheris.Fuzz()\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    atheris.instrument_all()\n",
      "    main()\n",
      "==================================================\n",
      "import atheris\n",
      "import sys\n",
      "from urllib.parse import urlencode, quote_plus\n",
      "\n",
      "def TestOneInput(data):\n",
      "    fdp = atheris.FuzzedDataProvider(data)\n",
      "    query = {}\n",
      "    for i in range(fdp.ConsumeIntInRange(0, 10)):\n",
      "        query[fdp.ConsumeUnicodeNoSurrogates(sys.maxsize)] = fdp.ConsumeUnicodeNoSurrogates(sys.maxsize)\n",
      "    doseq = fdp.ConsumeBool()\n",
      "    safe = fdp.ConsumeString(sys.maxsize)\n",
      "    encoding = fdp.ConsumeString(sys.maxsize)\n",
      "    errors = fdp.ConsumeString(sys.maxsize)\n",
      "    quote_via = quote_plus\n",
      "\n",
      "    try:\n",
      "        urlencode(query, doseq=doseq, safe=safe, encoding=encoding, errors=errors, quote_via=quote_via)\n",
      "    except Exception:\n",
      "        pass\n",
      "\n",
      "def main():\n",
      "    atheris.Setup(sys.argv, TestOneInput)\n",
      "    atheris.Fuzz()\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    atheris.instrument_all()\n",
      "    main()\n"
     ]
    }
   ],
   "source": [
    "# LLMChain example 1\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "from langfuzzDB import Library, LibraryFile, create_tables, get_engine\n",
    "from sqlalchemy.orm import Session\n",
    "import inspect\n",
    "import urllib3\n",
    "import openai\n",
    "import os\n",
    "\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "http_libs = {\n",
    " 'urllib3': {\n",
    " 'github': 'https://github.com/urllib3/urllib3',\n",
    " 'docs': 'https://urllib3.readthedocs.io/en/stable/'\n",
    "},\n",
    " 'requests': {\n",
    " 'github': 'https://github.com/psf/requests',\n",
    " 'docs': 'https://requests.readthedocs.io/en/latest/'\n",
    " },\n",
    "'aiohttp': {\n",
    " 'github': 'https://github.com/aio-libs/aiohttp/',\n",
    " 'docs': 'https://docs.aiohttp.org/en/stable/'\n",
    " },\n",
    " 'twisted': {\n",
    " 'github': 'https://github.com/twisted/twisted',\n",
    " 'docs': 'https://docs.twisted.org/en/stable/'\n",
    " }\n",
    "}\n",
    "\n",
    "lib = 'urllib3'\n",
    "\n",
    "#create a prompt\n",
    "def create_prompt(prompt_template, target_function):\n",
    "    prompt = prompt_template + f\"{target_function}\\n\"\n",
    "    return prompt\n",
    "\n",
    "#call GPT3 to generate a test\n",
    "def generate_test(prompt):\n",
    "    response = openai.ChatCompletion.create(\n",
    "    model='gpt-3.5-turbo',\n",
    "      messages=[\n",
    "        {\"role\": \"system\", \"content\": prompt}],\n",
    "    max_tokens=1000,\n",
    "    temperature=0,\n",
    ")\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "# get any fuzz files from the database\n",
    "def get_fuzz_files_contents(library_name, sqlitedb):\n",
    "    engine = get_engine(sqlitedb)\n",
    "    create_tables(engine)\n",
    "    session = Session(engine)\n",
    "    \n",
    "    fuzz_files = session.query(LibraryFile).filter(LibraryFile.library_name == library_name, LibraryFile.fuzz_test == True).all()\n",
    "    \n",
    "    file_data = []\n",
    "    for file in fuzz_files:\n",
    "        file_data.append((file.file_name, file.contents))\n",
    "\n",
    "    session.close()\n",
    "    \n",
    "    return file_data\n",
    "\n",
    "# add the fuzz files to the prompt\n",
    "def add_fuzz_files_to_prompt(file_data):\n",
    "    fuzz_prompt_context = ''\n",
    "    for file_name, contents in file_data:\n",
    "        fuzz_prompt_context += f\"example fuzzer for {file_name}:\\n{contents}\\n\"\n",
    "    return fuzz_prompt_context\n",
    "\n",
    "# get the functions from the target library\n",
    "def get_functions_from_module(module):\n",
    "    funcs = {}\n",
    "    for name, obj in inspect.getmembers(module):\n",
    "        if inspect.isfunction(obj):\n",
    "            funcs.update({name: (inspect.getsource(obj))})\n",
    "    return funcs\n",
    "\n",
    "# create a fuzz test\n",
    "def create_fuzz_test(prompt_template, target_function):\n",
    "    prompt = create_prompt(prompt_template, target_function)\n",
    "    fuzz_test = generate_test(prompt)\n",
    "    return fuzz_test\n",
    "\n",
    "def get_priority_funcs(all_funcs, priority_radon_funcs):\n",
    "    funcs = {}\n",
    "    for func, contents in all_funcs.items():\n",
    "        if func in priority_radon_funcs:\n",
    "            funcs.update({func: contents})\n",
    "    return funcs\n",
    "\n",
    "\n",
    "base_template = open(\"prompts/base-atheris-prompt.py\", \"r\").read() \n",
    "file_data = get_fuzz_files_contents(lib, 'langfuzz.db')\n",
    "fuzz_prompt_context = add_fuzz_files_to_prompt(file_data)\n",
    "\n",
    "# combine the prompt template with the fuzzer files\n",
    "prompt_template = base_template + fuzz_prompt_context + \"write an atheris fuzzer for the following function:\\n\"\n",
    "\n",
    "all_funcs = get_functions_from_module('urllib3')\n",
    "priority_radon_funcs = langfuzz_recon.radon_metrics('urllib3')\n",
    "\n",
    "funcs = get_priority_funcs(all_funcs, priority_radon_funcs)\n",
    "\n",
    "for func, contents in funcs.items():\n",
    "  fuzz_test = create_fuzz_test(prompt_template, contents)\n",
    "  print(\"=\"* 50)\n",
    "  print(fuzz_test)\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agent example\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "# openai.api_key = \"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\"\n",
    "from llm_agents import Agent, ChatLLM, PythonREPLTool, HackerNewsSearchTool, SerpAPITool\n",
    "\n",
    "source = \"\"\"\n",
    "import atheris\n",
    "import sys\n",
    "\n",
    "@atheris.instrument_func\n",
    "def TestOneInput(data):\n",
    "    fdp = atheris.FuzzedDataProvider(data)\n",
    "    a = fdp.ConsumeInt()\n",
    "    b = fdp.ConsumeInt()\n",
    "    try:\n",
    "        add(a, b)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def main():\n",
    "    atheris.Setup(sys.argv, TestOneInput)\n",
    "    atheris.Fuzz()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\"\"\" \n",
    "\n",
    "\n",
    "agent = Agent(llm=ChatLLM(), tools=[PythonREPLTool()])\n",
    "result = agent.run(source)\n",
    "\n",
    "print(f\"Final answer is {result}\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first section of code setsup all the values. we need for our session.\n",
    "\n",
    "We will eventually make this to feed in a single github url.\n",
    "\n",
    "Possibly hardcode some values like the sqlitedb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "\n",
    "from langfuzz.langfuzz import LangFuzz\n",
    "from langfuzz.langfuzz_recon import LangFuzzRecon\n",
    "\n",
    "from llm_agent import Agent, ChatLLM, PythonREPLTool, PythonREPLFuzzTool\n",
    "\n",
    "lib = 'urllib3'\n",
    "repo_path = 'github_repos'\n",
    "sqlitedb = 'langfuzz.db'\n",
    "prompts_path = \"../prompts/base-atheris-prompt.py\"\n",
    "\n",
    "http_libs = {\n",
    "    'urllib3': {\n",
    "    'github': 'https://github.com/urllib3/urllib3',\n",
    "    'docs': 'https://urllib3.readthedocs.io/en/stable/'\n",
    "    }}\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first part of the workflow is to learn about the libary. An easy path to automation is downloading code, finding any existing fuzz files, running a function compexity scan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oss-fuzz already exists, skipping download.\n",
      "Cloning urllib3 from https://github.com/urllib3/urllib3...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set up Recon object, specify path to github repos and path to sqlite db\n",
    "# repo_path = 'github_repos', sqlitedb = 'langfuzz.db'\n",
    "from langfuzz.langfuzz import LangFuzz\n",
    "from langfuzz.langfuzz_recon import LangFuzzRecon\n",
    "\n",
    "# This is the main class for the library, it downloads the github repos\n",
    "# finds the fuzz files generates the radon metrics \n",
    "# and stores everything in the database\n",
    "langfuzz_recon = LangFuzzRecon(repo_path, sqlitedb)\n",
    "\n",
    "# With the recon object we can get the functions and code from the library\n",
    "for library_name, lib_data in http_libs.items():\n",
    "all_functions = langfuzz_recon.get_functions_and_code_from_library(library_name)\n",
    "priority_radon_funcs\n",
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
