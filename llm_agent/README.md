	I am working on creating a python ReAct agent to use with openai's gpt4 llm. 

	Agents are a way to leverage the ability of LLMs to understand and act on prompts. An Agent is an LLM that has been given a clever initial prompt. The prompt tells the LLM to break down the process of answering a complex query into a sequence of steps that are resolved one at a time.

	At a high level the agent works like this:
	1) It gets instructed by a prompt which tells it the basic way to solve a task using tools. 

	2) Tools are custom build components which the agent can use, for example PythonREPLTool to run python

	3) The agent runs in a loop of Thought, Action, Observation, Thought,
	  	The Thought and Action are the parts which are generated by an LLM. An action can either be using a tool and observing its output, or returning to the user.
	  	The Observation is generated by using a tool (for example the print outputs of Python)

	4) The LLM gets the new information appended to the prompt in each loop cycle and thus can act on that information.
	    
	5) Once the agent has enough information it provides the final answer.


	Our example code has the following format:
	"
	Question: the input question you must answer
	Thought: comment on what you want to do next
	Action: the action to take, exactly one element of [{tool_names}]
	Action Input: the input to the action
	Observation: the result of the action
	... (this Thought/Action/Action Input/Observation repeats N times, use it until you are sure of the answer)
	Thought: I now know the final answer
	Final Answer: your final answer to the original input question

	Begin!

	Question: {question}
	Thought: {previous_responses}
	"


	Our specific code should analyze and debug previously generated python code. At a high level I want my agent to use this flow:

	1) Question: from user to LLM - prompt = 'Review this code and fix if any errors. Return only code, no comments or conversational text' + python_code

	2) Thought: prompt response from LLM  - responds with something like: 
		a) 'I need to modify code and use the PythonREPLTool to run and review this code'

	3) Action: from LLM - Action to take like: 
		a) 'I need to run the python_code with the provided PythonREPLTool' or
		b) 'modify python_code to fix errors, then run modified python_code in PythonREPLTool'

	4) Action Input: Tool- run python_code in PythonREPLTools to obtain python_repl_output.

	5) Observation: Review results of Action Input/tool - does python_code run without errors? 

		If code executed successfully without errors we return the working python_code snippet to the Final Answer.

		Else if it does not run; return prompt = "python_code + python_repl_output + 'Review this code and output and fix an errors. Return only code, no comments or conversational text' to step 2 and repeat process.

	6) Final Answer - executable and error free python_code or max loop message.


	Some notes on how our implementation is different than the example agent.py:

	I am mostly sending in not working code and would like the LLM to debug and fix automatically.

	We need to keep track of the most recent python_code in our agent loop. No need to keep track of every non-functioning python_code string and error message.

	Every LLM prompt will include the "PROMPT_TEMPLATE + python_code + python_repl_output + 'Review this code and output and fix an errors'. Return only code, no comments or conversational text'". 

	No need to store and send every code version.

	"Tools" in this context can be anything that takes a string as input and outputs a string. We are exclusively running and observing python code output.

	Final answer should be working python_code or a 'Not able to fix message' if we reach the max loops of 5.



	Example agent.py:
	import datetime
	import re

	from pydantic import BaseModel
	from typing import List, Dict, Tuple
	from llm_agents.llm import ChatLLM
	from llm_agents.tools.base import ToolInterface
	from llm_agents.tools.python_repl import PythonREPLTool


	FINAL_ANSWER_TOKEN = "Final Answer:"
	OBSERVATION_TOKEN = "Observation:"
	THOUGHT_TOKEN = "Thought:"
	PROMPT_TEMPLATE = """Today is {today} and you can use tools to get new information. Answer the question as best as you can using the following tools: 

	{tool_description}

	Use the following format:

	Question: the input question you must answer
	Thought: comment on what you want to do next
	Action: the action to take, exactly one element of [{tool_names}]
	Action Input: the input to the action
	Observation: the result of the action
	... (this Thought/Action/Action Input/Observation repeats N times, use it until you are sure of the answer)
	Thought: I now know the final answer
	Final Answer: your final answer to the original input question

	Begin!

	Question: {question}
	Thought: {previous_responses}
	"""

	class Agent(BaseModel):
	    llm: ChatLLM
	    tools: List[ToolInterface]
	    prompt_template: str = PROMPT_TEMPLATE
	    max_loops: int = 5
	    # The stop pattern is used, so the LLM does not hallucinate until the end
	    stop_pattern: List[str] = [f'\n{OBSERVATION_TOKEN}', f'\n\t{OBSERVATION_TOKEN}']

	    @property
	    def tool_description(self) -> str:
	        return "\n".join([f"{tool.name}: {tool.description}" for tool in self.tools])

	    @property
	    def tool_names(self) -> str:
	        return ",".join([tool.name for tool in self.tools])

	    @property
	    def tool_by_names(self) -> Dict[str, ToolInterface]:
	        return {tool.name: tool for tool in self.tools}

	    def run(self, question: str):
	        previous_responses = []
	        num_loops = 0
	        prompt = self.prompt_template.format(
	                today = datetime.date.today(),
	                tool_description=self.tool_description,
	                tool_names=self.tool_names,
	                question=question,
	                previous_responses='{previous_responses}'
	        )
	        print(prompt.format(previous_responses=''))
	        while num_loops < self.max_loops:
	            num_loops += 1
	            curr_prompt = prompt.format(previous_responses='\n'.join(previous_responses))
	            generated, tool, tool_input = self.decide_next_action(curr_prompt)
	            if tool == 'Final Answer':
	                return tool_input
	            if tool not in self.tool_by_names:
	                raise ValueError(f"Unknown tool: {tool}")
	            tool_result = self.tool_by_names[tool].use(tool_input)
	            generated += f"\n{OBSERVATION_TOKEN} {tool_result}\n{THOUGHT_TOKEN}"
	            print(generated)
	            previous_responses.append(generated)

	    def decide_next_action(self, prompt: str) -> str:
	        generated = self.llm.generate(prompt, stop=self.stop_pattern)
	        tool, tool_input = self._parse(generated)
	        return generated, tool, tool_input

	    def _parse(self, generated: str) -> Tuple[str, str]:
	        if FINAL_ANSWER_TOKEN in generated:
	            return "Final Answer", generated.split(FINAL_ANSWER_TOKEN)[-1].strip()
	        regex = r"Action: [\[]?(.*?)[\]]?[\n]*Action Input:[\s]*(.*)"
	        match = re.search(regex, generated, re.DOTALL)
	        if not match:
	            raise ValueError(f"Output of LLM is not parsable for next tool use: `{generated}`")
	        tool = match.group(1).strip()
	        tool_input = match.group(2)
	        return tool, tool_input.strip(" ").strip('"')


	if __name__ == '__main__':
	    agent = Agent(llm=ChatLLM(), tools=[PythonREPLTool()])
	    result = agent.run("What is 7 * 9 - 34 in Python?")

	    print(f"Final answer is {result}")



	Write a new code-agent.py file that meets all the requirements.

	Insert this at the bottom to test: 
	if __name__ == '__main__':
		python = """for fizzbuzz in range(51):
	    if fizzbuzz % 3 == 0 and fizzbuzz % 5 == 0:
	        print("fizzbuzz")
	        continue
	    elif fizzbuz % 3 == 0:
	        print("fizz")
	        continue
	    elif fizzbuzz % 5 == 0:
	        print("buzz")
	        continue
	    print(fizzbuzz)
		"""
	    agent = Agent(llm=ChatLLM(), tools=[PythonREPLTool()])
	    result = agent.run(python)

	    print(f"Final answer is {result}")


