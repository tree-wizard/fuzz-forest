{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "import atheris\n",
      "import sys\n",
      "from io import BytesIO\n",
      "import random\n",
      "import string\n",
      "import six\n",
      "\n",
      "def choose_boundary():\n",
      "    \"\"\"\n",
      "    Our implementation of choose_boundary function.\n",
      "    \"\"\"\n",
      "    return ''.join(random.choice(string.ascii_letters + string.digits) for _ in range(30))\n",
      "\n",
      "def iter_field_objects(fields):\n",
      "    \"\"\"\n",
      "    Our implementation of iter_field_objects function.\n",
      "    \"\"\"\n",
      "    if isinstance(fields, dict):\n",
      "        fields = list(fields.items())\n",
      "\n",
      "    for field in fields:\n",
      "        if isinstance(field, tuple):\n",
      "            yield RequestField(*field)\n",
      "        else:\n",
      "            yield field\n",
      "\n",
      "def b(data):\n",
      "    \"\"\"\n",
      "    Our implementation of b function.\n",
      "    \"\"\"\n",
      "    if isinstance(data, six.text_type):\n",
      "        return data.encode('utf-8')\n",
      "    return data\n",
      "\n",
      "class RequestField(object):\n",
      "    \"\"\"\n",
      "    Our implementation of RequestField class.\n",
      "    \"\"\"\n",
      "    def __init__(self, name, data, filename=None, headers=None):\n",
      "        self.name = name\n",
      "        self.data = data\n",
      "        self.filename = filename\n",
      "        self.headers = headers or {}\n",
      "\n",
      "    def render_headers(self):\n",
      "        \"\"\"\n",
      "        Our implementation of render_headers function.\n",
      "        \"\"\"\n",
      "        header_items = []\n",
      "\n",
      "        disposition = 'form-data; name=\"%s\"' % self.name\n",
      "        if self.filename:\n",
      "            disposition += '; filename=\"%s\"' % self.filename\n",
      "        header_items.append(('Content-Disposition', disposition))\n",
      "\n",
      "        content_type = self.headers.get('Content-Type', 'application/octet-stream')\n",
      "        header_items.append(('Content-Type', content_type))\n",
      "\n",
      "        return b('\\r\\n'.join('%s: %s' % (header, value) for header, value in header_items) + '\\r\\n\\r\\n')\n",
      "\n",
      "def TestOneInput(data):\n",
      "    fdp = atheris.FuzzedDataProvider(data)\n",
      "    fields = {}\n",
      "    for i in range(0, fdp.ConsumeIntInRange(0, 10)):\n",
      "        name = fdp.ConsumeString(sys.maxsize)\n",
      "        data = fdp.ConsumeString(sys.maxsize)\n",
      "        filename = None if fdp.ConsumeBool() else fdp.ConsumeString(sys.maxsize)\n",
      "        headers = None if fdp.ConsumeBool() else {fdp.ConsumeString(sys.maxsize): fdp.ConsumeString(sys.maxsize)}\n",
      "        fields[name] = RequestField(name, data, filename, headers)\n",
      "\n",
      "    boundary = None if fdp.ConsumeBool() else choose_boundary()\n",
      "\n",
      "    encode_multipart_formdata(fields, boundary)\n",
      "\n",
      "def main():\n",
      "    atheris.Setup(sys.argv, TestOneInput)\n",
      "    atheris.Fuzz()\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    atheris.instrument_all()\n",
      "    main()\n",
      "==================================================\n",
      "import atheris\n",
      "import sys\n",
      "from urllib.parse import urlencode, quote_plus\n",
      "\n",
      "def TestOneInput(data):\n",
      "    fdp = atheris.FuzzedDataProvider(data)\n",
      "    query = {}\n",
      "    for i in range(fdp.ConsumeIntInRange(0, 10)):\n",
      "        query[fdp.ConsumeUnicodeNoSurrogates(sys.maxsize)] = fdp.ConsumeUnicodeNoSurrogates(sys.maxsize)\n",
      "    doseq = fdp.ConsumeBool()\n",
      "    safe = fdp.ConsumeString(sys.maxsize)\n",
      "    encoding = fdp.ConsumeString(sys.maxsize)\n",
      "    errors = fdp.ConsumeString(sys.maxsize)\n",
      "    quote_via = quote_plus\n",
      "\n",
      "    try:\n",
      "        urlencode(query, doseq=doseq, safe=safe, encoding=encoding, errors=errors, quote_via=quote_via)\n",
      "    except Exception:\n",
      "        pass\n",
      "\n",
      "def main():\n",
      "    atheris.Setup(sys.argv, TestOneInput)\n",
      "    atheris.Fuzz()\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    atheris.instrument_all()\n",
      "    main()\n"
     ]
    }
   ],
   "source": [
    "# LLMChain example 1\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "from langfuzzDB import Library, LibraryFile, create_tables, get_engine\n",
    "from sqlalchemy.orm import Session\n",
    "import inspect\n",
    "import urllib3\n",
    "import openai\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "http_libs = {\n",
    " 'urllib3': {\n",
    " 'github': 'https://github.com/urllib3/urllib3',\n",
    " 'docs': 'https://urllib3.readthedocs.io/en/stable/'\n",
    "},\n",
    " 'requests': {\n",
    " 'github': 'https://github.com/psf/requests',\n",
    " 'docs': 'https://requests.readthedocs.io/en/latest/'\n",
    " },\n",
    "'aiohttp': {\n",
    " 'github': 'https://github.com/aio-libs/aiohttp/',\n",
    " 'docs': 'https://docs.aiohttp.org/en/stable/'\n",
    " },\n",
    " 'twisted': {\n",
    " 'github': 'https://github.com/twisted/twisted',\n",
    " 'docs': 'https://docs.twisted.org/en/stable/'\n",
    " }\n",
    "}\n",
    "\n",
    "lib = 'urllib3'\n",
    "\n",
    "#create a prompt\n",
    "def create_prompt(prompt_template, target_function):\n",
    "    prompt = prompt_template + f\"{target_function}\\n\"\n",
    "    return prompt\n",
    "\n",
    "#call GPT3 to generate a test\n",
    "def generate_test(prompt):\n",
    "    response = openai.ChatCompletion.create(\n",
    "    model='gpt-3.5-turbo',\n",
    "      messages=[\n",
    "        {\"role\": \"system\", \"content\": prompt}],\n",
    "    max_tokens=1000,\n",
    "    temperature=0,\n",
    ")\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "# get any fuzz files from the database\n",
    "def get_fuzz_files_contents(library_name, sqlitedb):\n",
    "    engine = get_engine(sqlitedb)\n",
    "    create_tables(engine)\n",
    "    session = Session(engine)\n",
    "    \n",
    "    fuzz_files = session.query(LibraryFile).filter(LibraryFile.library_name == library_name, LibraryFile.fuzz_test == True).all()\n",
    "    \n",
    "    file_data = []\n",
    "    for file in fuzz_files:\n",
    "        file_data.append((file.file_name, file.contents))\n",
    "\n",
    "    session.close()\n",
    "    \n",
    "    return file_data\n",
    "\n",
    "# add the fuzz files to the prompt\n",
    "def add_fuzz_files_to_prompt(file_data):\n",
    "    fuzz_prompt_context = ''\n",
    "    for file_name, contents in file_data:\n",
    "        fuzz_prompt_context += f\"example fuzzer for {file_name}:\\n{contents}\\n\"\n",
    "    return fuzz_prompt_context\n",
    "\n",
    "# get the functions from the target library\n",
    "def get_functions_from_module(module):\n",
    "    funcs = {}\n",
    "    for name, obj in inspect.getmembers(module):\n",
    "        if inspect.isfunction(obj):\n",
    "            funcs.update({name: (inspect.getsource(obj))})\n",
    "    return funcs\n",
    "\n",
    "# create a fuzz test\n",
    "def create_fuzz_test(prompt_template, target_function):\n",
    "    prompt = create_prompt(prompt_template, target_function)\n",
    "    fuzz_test = generate_test(prompt)\n",
    "    return fuzz_test\n",
    "\n",
    "def get_priority_funcs(all_funcs, priority_radon_funcs):\n",
    "    funcs = {}\n",
    "    for func, contents in all_funcs.items():\n",
    "        if func in priority_radon_funcs:\n",
    "            funcs.update({func: contents})\n",
    "    return funcs\n",
    "\n",
    "\n",
    "base_template = open(\"prompts/base-atheris-prompt.py\", \"r\").read() \n",
    "file_data = get_fuzz_files_contents(lib, 'langfuzz.db')\n",
    "fuzz_prompt_context = add_fuzz_files_to_prompt(file_data)\n",
    "\n",
    "# combine the prompt template with the fuzzer files\n",
    "prompt_template = base_template + fuzz_prompt_context + \"write an atheris fuzzer for the following function:\\n\"\n",
    "\n",
    "all_funcs = get_functions_from_module('urllib3')\n",
    "priority_radon_funcs = langfuzz_recon.radon_metrics('urllib3')\n",
    "\n",
    "funcs = get_priority_funcs(all_funcs, priority_radon_funcs)\n",
    "\n",
    "for func, contents in funcs.items():\n",
    "  fuzz_test = create_fuzz_test(prompt_template, contents)\n",
    "  print(\"=\"* 50)\n",
    "  print(fuzz_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agent example\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "# openai.api_key = \"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\"\n",
    "from llm_agents import Agent, ChatLLM, PythonREPLTool, HackerNewsSearchTool, SerpAPITool\n",
    "\n",
    "source = \"\"\"\n",
    "import atheris\n",
    "import sys\n",
    "\n",
    "@atheris.instrument_func\n",
    "def TestOneInput(data):\n",
    "    fdp = atheris.FuzzedDataProvider(data)\n",
    "    a = fdp.ConsumeInt()\n",
    "    b = fdp.ConsumeInt()\n",
    "    try:\n",
    "        add(a, b)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def main():\n",
    "    atheris.Setup(sys.argv, TestOneInput)\n",
    "    atheris.Fuzz()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\"\"\" \n",
    "\n",
    "\n",
    "agent = Agent(llm=ChatLLM(), tools=[PythonREPLTool()])\n",
    "result = agent.run(source)\n",
    "\n",
    "print(f\"Final answer is {result}\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first part of the workflow is to learn about the libary. An easy path to automation is downloading code, finding any existing fuzz files, running a function compexity scan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Library urllib3 already exists, skipping.\n",
      "Library aiohttp already exists, skipping.\n",
      "Library twisted already exists, skipping.\n",
      "oss-fuzz already exists, skipping download.\n",
      "urllib3 already exists, skipping download.\n",
      "aiohttp already exists, skipping download.\n",
      "twisted already exists, skipping download.\n",
      "File fuzz_requests.py already exists for library urllib3, skipping.\n",
      "File fuzz_urlparse.py already exists for library urllib3, skipping.\n",
      "File fuzz_web_request.py already exists for library aiohttp, skipping.\n",
      "File fuzz_payload_url.py already exists for library aiohttp, skipping.\n",
      "File fuzz_http_parser.py already exists for library aiohttp, skipping.\n",
      "File fuzz_multipart.py already exists for library aiohttp, skipping.\n",
      "File fuzz_http_payload_parser.py already exists for library aiohttp, skipping.\n",
      "twisted Repo does not exist in oss-fuzz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "\n",
    "from langfuzz.langfuzz_recon import LangFuzzRecon\n",
    "\n",
    "lib = 'urllib3'\n",
    "repo_path = 'github_repos'\n",
    "sqlitedb = 'langfuzz.db'\n",
    "\n",
    "# format can be either a string or a dictionary\n",
    "http_libs = {\n",
    "    'urllib3': {\n",
    "        'github': 'https://github.com/urllib3/urllib3',\n",
    "        'docs': 'https://urllib3.readthedocs.io/en/stable/'\n",
    "    },\n",
    "    'aiohttp': 'https://github.com/aio-libs/aiohttp/',\n",
    "    'twisted': {\n",
    "        'github': 'https://github.com/twisted/twisted',\n",
    "        'docs': 'https://docs.twisted.org/en/stable/'\n",
    " }}\n",
    "\n",
    "# This is the main class for the Recon library, it downloads the github repos\n",
    "# finds the fuzz files generates the radon metrics \n",
    "# and stores everything in the database\n",
    "langfuzz_recon = LangFuzzRecon(sqlitedb, repo_path, http_libs, 'python')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now move into the fuzzer generation. Using the same data structures as before we first create a LangFuzz class to connect to our previously created database and load our base-prompt.py. Eventually we want the prompts to be automatically selected by language.\n",
    "\n",
    "We can then loop through the library_name's to generate fuzz tests for every function. But to make it a little more efficient I am experimenting with selecting 'good' functions to test. My first approach is to use the concept of cyclomatic complexity to find the most 'complex' functions with the 'radon' tool.\n",
    "\n",
    "So for our testing we are going to extract the complex functions for each library, defined by a score of C and below and write fuzz tests for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'LangFuzz' from 'langfuzz' (/home/x/fuzz-forest/langfuzz/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m\n\u001b[1;32m      2\u001b[0m sys\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mappend(\u001b[39m'\u001b[39m\u001b[39m/home/x/fuzz-forest/langfuzz\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangfuzz\u001b[39;00m \u001b[39mimport\u001b[39;00m LangFuzz\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mimportlib\u001b[39;00m\n\u001b[1;32m      6\u001b[0m importlib\u001b[39m.\u001b[39mreload(LangFuzz)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'LangFuzz' from 'langfuzz' (/home/x/fuzz-forest/langfuzz/__init__.py)"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/x/fuzz-forest/langfuzz')\n",
    "from langfuzz.langfuzz import LangFuzz\n",
    "\n",
    "import importlib\n",
    "importlib.reload(LangFuzz)\n",
    "\n",
    "base_prompts_path = \"prompts/base-atheris-prompt.py\"\n",
    "sqlitedb = 'langfuzz.db'\n",
    "\n",
    "http_libs = {\n",
    "    'urllib3': {\n",
    "        'github': 'https://github.com/urllib3/urllib3',\n",
    "        'docs': 'https://urllib3.readthedocs.io/en/stable/'\n",
    "    },\n",
    "    'aiohttp': 'https://github.com/aio-libs/aiohttp/',\n",
    "    'twisted': {\n",
    "        'github': 'https://github.com/twisted/twisted',\n",
    "        'docs': 'https://docs.twisted.org/en/stable/'\n",
    " }}\n",
    "\n",
    "langfuzz = LangFuzz(sqlitedb, 'python', base_prompts_path)\n",
    "\n",
    "# This defines the score of radon complexity you want to pull from the database\n",
    "# A and B are the highest scores, C and D are the medium scores, and E and F are the lowest scores\n",
    "radon_score = ['C', 'D', 'E', 'F']\n",
    "# radon_score is optional, if you don't pass it, it will pull all the functions\n",
    "#priority_funcs = langfuzz.get_radon_functions_from_db('twisted', radon_score)\n",
    "#print(priority_funcs)\n",
    "priority_funcs = ['create_urllib3_context', 'ssl_wrap_socket','match_hostname', 'parse_url']\n",
    "\n",
    "# priority_funcs is optional, if you don't pass it, it will generate fuzz tests for all the functions\n",
    "langfuzz.generate_fuzz_tests('urllib3', priority_funcs)\n",
    "\n",
    "# We can also pass in the libs dictionary to generate fuzz tests for all the libraries\n",
    "#for library_name in http_libs.keys():\n",
    "#    priority_funcs = LangFuzz.get_radon_functions_from_db(library_name, radon_score)\n",
    "#    LangFuzz.generate_fuzz_tests(library_name, priority_funcs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LangFuzz', 'LangFuzzRecon', 'Library', 'LibraryFile', 'Session', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', '__warningregistry__', 'create_tables', 'get_engine', 'importlib', 'inspect', 'openai', 'os', 'pkgutil']\n"
     ]
    }
   ],
   "source": [
    "import langfuzz.langfuzz\n",
    "print(dir(langfuzz.langfuzz))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code and library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "urllib3\n",
      "aiohttp\n",
      "twisted\n"
     ]
    }
   ],
   "source": [
    "http_libs = {\n",
    "    'urllib3': {\n",
    "        'github': 'https://github.com/urllib3/urllib3',\n",
    "        'docs': 'https://urllib3.readthedocs.io/en/stable/'\n",
    "    },\n",
    "    'aiohttp': 'https://github.com/aio-libs/aiohttp/',\n",
    "    'twisted': {\n",
    "        'github': 'https://github.com/twisted/twisted',\n",
    "        'docs': 'https://docs.twisted.org/en/stable/'\n",
    " }}\n",
    "\n",
    "for library_name in http_libs.keys():\n",
    "    print(library_name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
