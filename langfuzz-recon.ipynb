{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "urllib3 already exists, skipping download.\n",
      "requests already exists, skipping download.\n",
      "aiohttp already exists, skipping download.\n",
      "twisted already exists, skipping download.\n",
      "oss-fuzz already exists, skipping download.\n",
      "twisted Repo does not exist\n",
      "{'urllib3': ['github_repos/oss-fuzz/projects/urllib3/fuzz_requests.py', 'github_repos/oss-fuzz/projects/urllib3/fuzz_urlparse.py'], 'requests': ['github_repos/oss-fuzz/projects/requests/fuzz_server.py'], 'aiohttp': ['github_repos/oss-fuzz/projects/aiohttp/fuzz_web_request.py', 'github_repos/oss-fuzz/projects/aiohttp/fuzz_payload_url.py', 'github_repos/oss-fuzz/projects/aiohttp/fuzz_http_parser.py', 'github_repos/oss-fuzz/projects/aiohttp/fuzz_multipart.py', 'github_repos/oss-fuzz/projects/aiohttp/fuzz_http_payload_parser.py'], 'twisted': []}\n"
     ]
    }
   ],
   "source": [
    "# Extract github value from dictionary and download git repo to directory named after the dictionary\n",
    "import os\n",
    "import git\n",
    "\n",
    "from langfuzz.langfuzzDB import Library, LibraryFile, create_tables, get_engine\n",
    "from sqlalchemy.orm import Session\n",
    "\n",
    "http_libs = {\n",
    " 'urllib3': {\n",
    " 'github': 'https://github.com/urllib3/urllib3',\n",
    " 'docs': 'https://urllib3.readthedocs.io/en/stable/'\n",
    "},\n",
    " 'requests': {\n",
    " 'github': 'https://github.com/psf/requests',\n",
    " 'docs': 'https://requests.readthedocs.io/en/latest/'\n",
    " },\n",
    "'aiohttp': {\n",
    " 'github': 'https://github.com/aio-libs/aiohttp/',\n",
    " 'docs': 'https://docs.aiohttp.org/en/stable/'\n",
    " },\n",
    " 'twisted': {\n",
    " 'github': 'https://github.com/twisted/twisted',\n",
    " 'docs': 'https://docs.twisted.org/en/stable/'\n",
    " }\n",
    "}\n",
    "\n",
    "utils = {\n",
    " 'oss-fuzz': {\n",
    "\t 'github': 'https://github.com/google/oss-fuzz'\n",
    "\t }\n",
    " }\n",
    "\n",
    "# possibly refactor to accept a string or list of repo strings\n",
    "def download_github_repos(lib_dicts, repo_path):\n",
    "    for lib_dict in lib_dicts:\n",
    "        \n",
    "      for lib_name, lib_data in lib_dict.items():\n",
    "            repo_dir = os.path.join(repo_path, lib_name)\n",
    "            if not os.path.exists(repo_dir):\n",
    "                git_url = lib_data[\"github\"]\n",
    "                print(f\"Cloning {lib_name} from {git_url}...\")\n",
    "                git.Repo.clone_from(git_url, repo_dir)\n",
    "            else:\n",
    "                print(f\"{lib_name} already exists, skipping download.\")\n",
    "\n",
    "# iterate http_libs dictionary and find all python fuzz files\n",
    "# path = repo_path + http_libs[key]\n",
    "# fuzz files start with \"fuzz\" and end with \".py\"\n",
    "# save the fuzz files to a dictionary with the key being the library name and the value being the path to the fuzz file\n",
    "def get_fuzz_files(lib_dict, repo_path):\n",
    "    fuzz_files = {}\n",
    "    for key in lib_dict:\n",
    "        path = repo_path + '/oss-fuzz/projects/' + str(key)\n",
    "        fuzz_files[str(key)] = []\n",
    "        # if the path exists, find all fuzz files\n",
    "        if os.path.exists(path):\n",
    "            for root, dirs, files in os.walk(path):\n",
    "                for file in files:\n",
    "                    if file.startswith(\"fuzz\") and file.endswith(\".py\"):\n",
    "                        fuzz_files[key].append(os.path.join(root, file))\n",
    "        else:\n",
    "            print(f\"{key} Repo does not exist\")\n",
    "    return(fuzz_files)\n",
    "\n",
    "# save library info to sqlite database\n",
    "def save_libs(libs, sqlitedb, lang):\n",
    "    engine = get_engine(sqlitedb)\n",
    "    create_tables(engine)\n",
    "    session = Session(engine)\n",
    "\n",
    "    for library_name, lib_data in libs.items():\n",
    "        github_url = lib_data['github']\n",
    "        docs_url = lib_data['docs']\n",
    "        language = lang\n",
    "\n",
    "        existing_lib = session.query(Library).filter_by(library_name=library_name).first()\n",
    "        if existing_lib is None:\n",
    "            lib = Library(library_name=library_name, github_url=github_url, docs_url=docs_url, language=language)\n",
    "            session.add(lib)\n",
    "        else:\n",
    "            print(f\"Library {library_name} already exists, skipping.\")\n",
    "\n",
    "    session.commit()\n",
    "    session.close()\n",
    "\n",
    "# save fuzz files to sqlite database\n",
    "def save_fuzz_files(fuzz_files, sqlitedb, lang):\n",
    "    engine = get_engine(sqlitedb)\n",
    "    create_tables(engine)\n",
    "    session = Session(engine)\n",
    "\n",
    "    for library_name, file_list in fuzz_files.items():\n",
    "        for file_path in file_list:\n",
    "            file_name = os.path.basename(file_path)\n",
    "            with open(file_path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "            first_source_line_index = next((index for index, line in enumerate(lines) if line.startswith(\"import\")), 0)\n",
    "            contents = \"\".join(lines[first_source_line_index:])\n",
    "\n",
    "            existing_file = session.query(LibraryFile).filter_by(library_name=library_name, file_name=file_name).first()\n",
    "            if existing_file is None:\n",
    "                lib_file = LibraryFile(library_name=library_name, file_name=file_name, contents=contents, generated=False, fuzz_test=True, type=\"fuzzer\")\n",
    "                session.add(lib_file)\n",
    "            else:\n",
    "                print(f\"File {file_name} already exists for library {library_name}, skipping.\")\n",
    "\n",
    "    session.commit()\n",
    "    session.close()\n",
    "\n",
    "\n",
    "def save_recon_data(libs, fuzz_files, sqlitedb, lang):\n",
    "    save_libs(libs, sqlitedb, lang)\n",
    "    save_fuzz_files(fuzz_files, sqlitedb, lang)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Set up\n",
    "repo_path = \"github_repos\"\n",
    "os.makedirs(repo_path) if not os.path.exists(repo_path) else None\n",
    "sqlitedb = \"langfuzz.db\"\n",
    "libs = [http_libs, utils]\n",
    "\n",
    "# Download repos from http_libs and utils dictionaries\n",
    "download_github_repos(libs, repo_path)\n",
    "# get fuzzed files from oss-fuzz repo\n",
    "fuzz_files = get_fuzz_files(http_libs, repo_path)\n",
    "print(fuzz_files)\n",
    "# save fuzzed files and library info in sqlite database\n",
    "#save_recon_data(http_libs, fuzz_files, sqlitedb, 'python')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function Name: RLock\n",
      "Source Code:\n",
      "def RLock(*args, **kwargs):\n",
      "    \"\"\"Factory function that returns a new reentrant lock.\n",
      "\n",
      "    A reentrant lock must be released by the thread that acquired it. Once a\n",
      "    thread has acquired a reentrant lock, the same thread may acquire it again\n",
      "    without blocking; the thread must release it once for each time it has\n",
      "    acquired it.\n",
      "\n",
      "    \"\"\"\n",
      "    if _CRLock is None:\n",
      "        return _PyRLock(*args, **kwargs)\n",
      "    return _CRLock(*args, **kwargs)\n",
      "\n",
      "================================================================================\n",
      "Function Name: iterkeys\n",
      "Source Code:\n",
      "    def iterkeys(d, **kw):\n",
      "        return iter(d.keys(**kw))\n",
      "\n",
      "================================================================================\n",
      "Function Name: itervalues\n",
      "Source Code:\n",
      "    def itervalues(d, **kw):\n",
      "        return iter(d.values(**kw))\n",
      "\n",
      "================================================================================\n",
      "Function Name: _get_default_user_agent\n",
      "Source Code:\n",
      "def _get_default_user_agent():\n",
      "    return \"python-urllib3/%s\" % __version__\n",
      "\n",
      "================================================================================\n",
      "Function Name: _match_hostname\n",
      "Source Code:\n",
      "def _match_hostname(cert, asserted_hostname):\n",
      "    # Our upstream implementation of ssl.match_hostname()\n",
      "    # only applies this normalization to IP addresses so it doesn't\n",
      "    # match DNS SANs so we do the same thing!\n",
      "    stripped_hostname = asserted_hostname.strip(\"u[]\")\n",
      "    if is_ipaddress(stripped_hostname):\n",
      "        asserted_hostname = stripped_hostname\n",
      "\n",
      "    try:\n",
      "        match_hostname(cert, asserted_hostname)\n",
      "    except CertificateError as e:\n",
      "        log.warning(\n",
      "            \"Certificate did not match expected hostname: %s. Certificate: %s\",\n",
      "            asserted_hostname,\n",
      "            cert,\n",
      "        )\n",
      "        # Add cert to exception and reraise so client code can inspect\n",
      "        # the cert when catching the exception, if they want to\n",
      "        e._peer_cert = cert\n",
      "        raise\n",
      "\n",
      "================================================================================\n",
      "Function Name: assert_fingerprint\n",
      "Source Code:\n",
      "def assert_fingerprint(cert, fingerprint):\n",
      "    \"\"\"\n",
      "    Checks if given fingerprint matches the supplied certificate.\n",
      "\n",
      "    :param cert:\n",
      "        Certificate as bytes object.\n",
      "    :param fingerprint:\n",
      "        Fingerprint as string of hexdigits, can be interspersed by colons.\n",
      "    \"\"\"\n",
      "\n",
      "    fingerprint = fingerprint.replace(\":\", \"\").lower()\n",
      "    digest_length = len(fingerprint)\n",
      "    hashfunc = HASHFUNC_MAP.get(digest_length)\n",
      "    if not hashfunc:\n",
      "        raise SSLError(\"Fingerprint of invalid length: {0}\".format(fingerprint))\n",
      "\n",
      "    # We need encode() here for py32; works on py2 and p33.\n",
      "    fingerprint_bytes = unhexlify(fingerprint.encode())\n",
      "\n",
      "    cert_digest = hashfunc(cert).digest()\n",
      "\n",
      "    if not _const_compare_digest(cert_digest, fingerprint_bytes):\n",
      "        raise SSLError(\n",
      "            'Fingerprints did not match. Expected \"{0}\", got \"{1}\".'.format(\n",
      "                fingerprint, hexlify(cert_digest)\n",
      "            )\n",
      "        )\n",
      "\n",
      "================================================================================\n",
      "Function Name: create_proxy_ssl_context\n",
      "Source Code:\n",
      "def create_proxy_ssl_context(\n",
      "    ssl_version, cert_reqs, ca_certs=None, ca_cert_dir=None, ca_cert_data=None\n",
      "):\n",
      "    \"\"\"\n",
      "    Generates a default proxy ssl context if one hasn't been provided by the\n",
      "    user.\n",
      "    \"\"\"\n",
      "    ssl_context = create_urllib3_context(\n",
      "        ssl_version=resolve_ssl_version(ssl_version),\n",
      "        cert_reqs=resolve_cert_reqs(cert_reqs),\n",
      "    )\n",
      "\n",
      "    if (\n",
      "        not ca_certs\n",
      "        and not ca_cert_dir\n",
      "        and not ca_cert_data\n",
      "        and hasattr(ssl_context, \"load_default_certs\")\n",
      "    ):\n",
      "        ssl_context.load_default_certs()\n",
      "\n",
      "    return ssl_context\n",
      "\n",
      "================================================================================\n",
      "Function Name: create_urllib3_context\n",
      "Source Code:\n",
      "def create_urllib3_context(\n",
      "    ssl_version=None, cert_reqs=None, options=None, ciphers=None\n",
      "):\n",
      "    \"\"\"All arguments have the same meaning as ``ssl_wrap_socket``.\n",
      "\n",
      "    By default, this function does a lot of the same work that\n",
      "    ``ssl.create_default_context`` does on Python 3.4+. It:\n",
      "\n",
      "    - Disables SSLv2, SSLv3, and compression\n",
      "    - Sets a restricted set of server ciphers\n",
      "\n",
      "    If you wish to enable SSLv3, you can do::\n",
      "\n",
      "        from urllib3.util import ssl_\n",
      "        context = ssl_.create_urllib3_context()\n",
      "        context.options &= ~ssl_.OP_NO_SSLv3\n",
      "\n",
      "    You can do the same to enable compression (substituting ``COMPRESSION``\n",
      "    for ``SSLv3`` in the last line above).\n",
      "\n",
      "    :param ssl_version:\n",
      "        The desired protocol version to use. This will default to\n",
      "        PROTOCOL_SSLv23 which will negotiate the highest protocol that both\n",
      "        the server and your installation of OpenSSL support.\n",
      "    :param cert_reqs:\n",
      "        Whether to require the certificate verification. This defaults to\n",
      "        ``ssl.CERT_REQUIRED``.\n",
      "    :param options:\n",
      "        Specific OpenSSL options. These default to ``ssl.OP_NO_SSLv2``,\n",
      "        ``ssl.OP_NO_SSLv3``, ``ssl.OP_NO_COMPRESSION``, and ``ssl.OP_NO_TICKET``.\n",
      "    :param ciphers:\n",
      "        Which cipher suites to allow the server to select.\n",
      "    :returns:\n",
      "        Constructed SSLContext object with specified options\n",
      "    :rtype: SSLContext\n",
      "    \"\"\"\n",
      "    # PROTOCOL_TLS is deprecated in Python 3.10\n",
      "    if not ssl_version or ssl_version == PROTOCOL_TLS:\n",
      "        ssl_version = PROTOCOL_TLS_CLIENT\n",
      "\n",
      "    context = SSLContext(ssl_version)\n",
      "\n",
      "    context.set_ciphers(ciphers or DEFAULT_CIPHERS)\n",
      "\n",
      "    # Setting the default here, as we may have no ssl module on import\n",
      "    cert_reqs = ssl.CERT_REQUIRED if cert_reqs is None else cert_reqs\n",
      "\n",
      "    if options is None:\n",
      "        options = 0\n",
      "        # SSLv2 is easily broken and is considered harmful and dangerous\n",
      "        options |= OP_NO_SSLv2\n",
      "        # SSLv3 has several problems and is now dangerous\n",
      "        options |= OP_NO_SSLv3\n",
      "        # Disable compression to prevent CRIME attacks for OpenSSL 1.0+\n",
      "        # (issue #309)\n",
      "        options |= OP_NO_COMPRESSION\n",
      "        # TLSv1.2 only. Unless set explicitly, do not request tickets.\n",
      "        # This may save some bandwidth on wire, and although the ticket is encrypted,\n",
      "        # there is a risk associated with it being on wire,\n",
      "        # if the server is not rotating its ticketing keys properly.\n",
      "        options |= OP_NO_TICKET\n",
      "\n",
      "    context.options |= options\n",
      "\n",
      "    # Enable post-handshake authentication for TLS 1.3, see GH #1634. PHA is\n",
      "    # necessary for conditional client cert authentication with TLS 1.3.\n",
      "    # The attribute is None for OpenSSL <= 1.1.0 or does not exist in older\n",
      "    # versions of Python.  We only enable on Python 3.7.4+ or if certificate\n",
      "    # verification is enabled to work around Python issue #37428\n",
      "    # See: https://bugs.python.org/issue37428\n",
      "    if (cert_reqs == ssl.CERT_REQUIRED or sys.version_info >= (3, 7, 4)) and getattr(\n",
      "        context, \"post_handshake_auth\", None\n",
      "    ) is not None:\n",
      "        context.post_handshake_auth = True\n",
      "\n",
      "    def disable_check_hostname():\n",
      "        if (\n",
      "            getattr(context, \"check_hostname\", None) is not None\n",
      "        ):  # Platform-specific: Python 3.2\n",
      "            # We do our own verification, including fingerprints and alternative\n",
      "            # hostnames. So disable it here\n",
      "            context.check_hostname = False\n",
      "\n",
      "    # The order of the below lines setting verify_mode and check_hostname\n",
      "    # matter due to safe-guards SSLContext has to prevent an SSLContext with\n",
      "    # check_hostname=True, verify_mode=NONE/OPTIONAL. This is made even more\n",
      "    # complex because we don't know whether PROTOCOL_TLS_CLIENT will be used\n",
      "    # or not so we don't know the initial state of the freshly created SSLContext.\n",
      "    if cert_reqs == ssl.CERT_REQUIRED:\n",
      "        context.verify_mode = cert_reqs\n",
      "        disable_check_hostname()\n",
      "    else:\n",
      "        disable_check_hostname()\n",
      "        context.verify_mode = cert_reqs\n",
      "\n",
      "    # Enable logging of TLS session keys via defacto standard environment variable\n",
      "    # 'SSLKEYLOGFILE', if the feature is available (Python 3.8+). Skip empty values.\n",
      "    if hasattr(context, \"keylog_filename\"):\n",
      "        sslkeylogfile = os.environ.get(\"SSLKEYLOGFILE\")\n",
      "        if sslkeylogfile:\n",
      "            context.keylog_filename = sslkeylogfile\n",
      "\n",
      "    return context\n",
      "\n",
      "================================================================================\n",
      "Function Name: is_ipaddress\n",
      "Source Code:\n",
      "def is_ipaddress(hostname):\n",
      "    \"\"\"Detects whether the hostname given is an IPv4 or IPv6 address.\n",
      "    Also detects IPv6 addresses with Zone IDs.\n",
      "\n",
      "    :param str hostname: Hostname to examine.\n",
      "    :return: True if the hostname is an IP address, False otherwise.\n",
      "    \"\"\"\n",
      "    if not six.PY2 and isinstance(hostname, bytes):\n",
      "        # IDN A-label bytes are ASCII compatible.\n",
      "        hostname = hostname.decode(\"ascii\")\n",
      "    return bool(IPV4_RE.match(hostname) or BRACELESS_IPV6_ADDRZ_RE.match(hostname))\n",
      "\n",
      "================================================================================\n",
      "Function Name: match_hostname\n",
      "Source Code:\n",
      "def match_hostname(cert, hostname):\n",
      "    \"\"\"Verify that *cert* (in decoded format as returned by\n",
      "    SSLSocket.getpeercert()) matches the *hostname*.  RFC 2818 and RFC 6125\n",
      "    rules are followed, but IP addresses are not accepted for *hostname*.\n",
      "\n",
      "    CertificateError is raised on failure. On success, the function\n",
      "    returns nothing.\n",
      "    \"\"\"\n",
      "    if not cert:\n",
      "        raise ValueError(\n",
      "            \"empty or no certificate, match_hostname needs a \"\n",
      "            \"SSL socket or SSL context with either \"\n",
      "            \"CERT_OPTIONAL or CERT_REQUIRED\"\n",
      "        )\n",
      "    try:\n",
      "        # Divergence from upstream: ipaddress can't handle byte str\n",
      "        host_ip = ipaddress.ip_address(_to_unicode(hostname))\n",
      "    except (UnicodeError, ValueError):\n",
      "        # ValueError: Not an IP address (common case)\n",
      "        # UnicodeError: Divergence from upstream: Have to deal with ipaddress not taking\n",
      "        # byte strings.  addresses should be all ascii, so we consider it not\n",
      "        # an ipaddress in this case\n",
      "        host_ip = None\n",
      "    except AttributeError:\n",
      "        # Divergence from upstream: Make ipaddress library optional\n",
      "        if ipaddress is None:\n",
      "            host_ip = None\n",
      "        else:  # Defensive\n",
      "            raise\n",
      "    dnsnames = []\n",
      "    san = cert.get(\"subjectAltName\", ())\n",
      "    for key, value in san:\n",
      "        if key == \"DNS\":\n",
      "            if host_ip is None and _dnsname_match(value, hostname):\n",
      "                return\n",
      "            dnsnames.append(value)\n",
      "        elif key == \"IP Address\":\n",
      "            if host_ip is not None and _ipaddress_match(value, host_ip):\n",
      "                return\n",
      "            dnsnames.append(value)\n",
      "    if not dnsnames:\n",
      "        # The subject is only checked when there is no dNSName entry\n",
      "        # in subjectAltName\n",
      "        for sub in cert.get(\"subject\", ()):\n",
      "            for key, value in sub:\n",
      "                # XXX according to RFC 2818, the most specific Common Name\n",
      "                # must be used.\n",
      "                if key == \"commonName\":\n",
      "                    if _dnsname_match(value, hostname):\n",
      "                        return\n",
      "                    dnsnames.append(value)\n",
      "    if len(dnsnames) > 1:\n",
      "        raise CertificateError(\n",
      "            \"hostname %r \"\n",
      "            \"doesn't match either of %s\" % (hostname, \", \".join(map(repr, dnsnames)))\n",
      "        )\n",
      "    elif len(dnsnames) == 1:\n",
      "        raise CertificateError(\"hostname %r doesn't match %r\" % (hostname, dnsnames[0]))\n",
      "    else:\n",
      "        raise CertificateError(\n",
      "            \"no appropriate commonName or subjectAltName fields were found\"\n",
      "        )\n",
      "\n",
      "================================================================================\n",
      "Function Name: resolve_cert_reqs\n",
      "Source Code:\n",
      "def resolve_cert_reqs(candidate):\n",
      "    \"\"\"\n",
      "    Resolves the argument to a numeric constant, which can be passed to\n",
      "    the wrap_socket function/method from the ssl module.\n",
      "    Defaults to :data:`ssl.CERT_REQUIRED`.\n",
      "    If given a string it is assumed to be the name of the constant in the\n",
      "    :mod:`ssl` module or its abbreviation.\n",
      "    (So you can specify `REQUIRED` instead of `CERT_REQUIRED`.\n",
      "    If it's neither `None` nor a string we assume it is already the numeric\n",
      "    constant which can directly be passed to wrap_socket.\n",
      "    \"\"\"\n",
      "    if candidate is None:\n",
      "        return CERT_REQUIRED\n",
      "\n",
      "    if isinstance(candidate, str):\n",
      "        res = getattr(ssl, candidate, None)\n",
      "        if res is None:\n",
      "            res = getattr(ssl, \"CERT_\" + candidate)\n",
      "        return res\n",
      "\n",
      "    return candidate\n",
      "\n",
      "================================================================================\n",
      "Function Name: resolve_ssl_version\n",
      "Source Code:\n",
      "def resolve_ssl_version(candidate):\n",
      "    \"\"\"\n",
      "    like resolve_cert_reqs\n",
      "    \"\"\"\n",
      "    if candidate is None:\n",
      "        return PROTOCOL_TLS\n",
      "\n",
      "    if isinstance(candidate, str):\n",
      "        res = getattr(ssl, candidate, None)\n",
      "        if res is None:\n",
      "            res = getattr(ssl, \"PROTOCOL_\" + candidate)\n",
      "        return res\n",
      "\n",
      "    return candidate\n",
      "\n",
      "================================================================================\n",
      "Function Name: ssl_wrap_socket\n",
      "Source Code:\n",
      "def ssl_wrap_socket(\n",
      "    sock,\n",
      "    keyfile=None,\n",
      "    certfile=None,\n",
      "    cert_reqs=None,\n",
      "    ca_certs=None,\n",
      "    server_hostname=None,\n",
      "    ssl_version=None,\n",
      "    ciphers=None,\n",
      "    ssl_context=None,\n",
      "    ca_cert_dir=None,\n",
      "    key_password=None,\n",
      "    ca_cert_data=None,\n",
      "    tls_in_tls=False,\n",
      "):\n",
      "    \"\"\"\n",
      "    All arguments except for server_hostname, ssl_context, and ca_cert_dir have\n",
      "    the same meaning as they do when using :func:`ssl.wrap_socket`.\n",
      "\n",
      "    :param server_hostname:\n",
      "        When SNI is supported, the expected hostname of the certificate\n",
      "    :param ssl_context:\n",
      "        A pre-made :class:`SSLContext` object. If none is provided, one will\n",
      "        be created using :func:`create_urllib3_context`.\n",
      "    :param ciphers:\n",
      "        A string of ciphers we wish the client to support.\n",
      "    :param ca_cert_dir:\n",
      "        A directory containing CA certificates in multiple separate files, as\n",
      "        supported by OpenSSL's -CApath flag or the capath argument to\n",
      "        SSLContext.load_verify_locations().\n",
      "    :param key_password:\n",
      "        Optional password if the keyfile is encrypted.\n",
      "    :param ca_cert_data:\n",
      "        Optional string containing CA certificates in PEM format suitable for\n",
      "        passing as the cadata parameter to SSLContext.load_verify_locations()\n",
      "    :param tls_in_tls:\n",
      "        Use SSLTransport to wrap the existing socket.\n",
      "    \"\"\"\n",
      "    context = ssl_context\n",
      "    if context is None:\n",
      "        # Note: This branch of code and all the variables in it are no longer\n",
      "        # used by urllib3 itself. We should consider deprecating and removing\n",
      "        # this code.\n",
      "        context = create_urllib3_context(ssl_version, cert_reqs, ciphers=ciphers)\n",
      "\n",
      "    if ca_certs or ca_cert_dir or ca_cert_data:\n",
      "        try:\n",
      "            context.load_verify_locations(ca_certs, ca_cert_dir, ca_cert_data)\n",
      "        except (IOError, OSError) as e:\n",
      "            raise SSLError(e)\n",
      "\n",
      "    elif ssl_context is None and hasattr(context, \"load_default_certs\"):\n",
      "        # try to load OS default certs; works well on Windows (require Python3.4+)\n",
      "        context.load_default_certs()\n",
      "\n",
      "    # Attempt to detect if we get the goofy behavior of the\n",
      "    # keyfile being encrypted and OpenSSL asking for the\n",
      "    # passphrase via the terminal and instead error out.\n",
      "    if keyfile and key_password is None and _is_key_file_encrypted(keyfile):\n",
      "        raise SSLError(\"Client private key is encrypted, password is required\")\n",
      "\n",
      "    if certfile:\n",
      "        if key_password is None:\n",
      "            context.load_cert_chain(certfile, keyfile)\n",
      "        else:\n",
      "            context.load_cert_chain(certfile, keyfile, key_password)\n",
      "\n",
      "    try:\n",
      "        if hasattr(context, \"set_alpn_protocols\"):\n",
      "            context.set_alpn_protocols(ALPN_PROTOCOLS)\n",
      "    except NotImplementedError:  # Defensive: in CI, we always have set_alpn_protocols\n",
      "        pass\n",
      "\n",
      "    # If we detect server_hostname is an IP address then the SNI\n",
      "    # extension should not be used according to RFC3546 Section 3.1\n",
      "    use_sni_hostname = server_hostname and not is_ipaddress(server_hostname)\n",
      "    # SecureTransport uses server_hostname in certificate verification.\n",
      "    send_sni = (use_sni_hostname and HAS_SNI) or (\n",
      "        IS_SECURETRANSPORT and server_hostname\n",
      "    )\n",
      "    # Do not warn the user if server_hostname is an invalid SNI hostname.\n",
      "    if not HAS_SNI and use_sni_hostname:\n",
      "        warnings.warn(\n",
      "            \"An HTTPS request has been made, but the SNI (Server Name \"\n",
      "            \"Indication) extension to TLS is not available on this platform. \"\n",
      "            \"This may cause the server to present an incorrect TLS \"\n",
      "            \"certificate, which can cause validation failures. You can upgrade to \"\n",
      "            \"a newer version of Python to solve this. For more information, see \"\n",
      "            \"https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html\"\n",
      "            \"#ssl-warnings\",\n",
      "            SNIMissingWarning,\n",
      "        )\n",
      "\n",
      "    if send_sni:\n",
      "        ssl_sock = _ssl_wrap_socket_impl(\n",
      "            sock, context, tls_in_tls, server_hostname=server_hostname\n",
      "        )\n",
      "    else:\n",
      "        ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls)\n",
      "    return ssl_sock\n",
      "\n",
      "================================================================================\n",
      "Function Name: _encode_target\n",
      "Source Code:\n",
      "def _encode_target(target):\n",
      "    \"\"\"Percent-encodes a request target so that there are no invalid characters\"\"\"\n",
      "    path, query = TARGET_RE.match(target).groups()\n",
      "    target = _encode_invalid_chars(path, PATH_CHARS)\n",
      "    query = _encode_invalid_chars(query, QUERY_CHARS)\n",
      "    if query is not None:\n",
      "        target += \"?\" + query\n",
      "    return target\n",
      "\n",
      "================================================================================\n",
      "Function Name: _normalize_host\n",
      "Source Code:\n",
      "def _normalize_host(host, scheme):\n",
      "    \"\"\"\n",
      "    Normalize hosts for comparisons and use with sockets.\n",
      "    \"\"\"\n",
      "\n",
      "    host = normalize_host(host, scheme)\n",
      "\n",
      "    # httplib doesn't like it when we include brackets in IPv6 addresses\n",
      "    # Specifically, if we include brackets but also pass the port then\n",
      "    # httplib crazily doubles up the square brackets on the Host header.\n",
      "    # Instead, we need to make sure we never pass ``None`` as the port.\n",
      "    # However, for backward compatibility reasons we can't actually\n",
      "    # *assert* that.  See http://bugs.python.org/issue28539\n",
      "    if host.startswith(\"[\") and host.endswith(\"]\"):\n",
      "        host = host[1:-1]\n",
      "    return host\n",
      "\n",
      "================================================================================\n",
      "Function Name: assert_header_parsing\n",
      "Source Code:\n",
      "def assert_header_parsing(headers):\n",
      "    \"\"\"\n",
      "    Asserts whether all headers have been successfully parsed.\n",
      "    Extracts encountered errors from the result of parsing headers.\n",
      "\n",
      "    Only works on Python 3.\n",
      "\n",
      "    :param http.client.HTTPMessage headers: Headers to verify.\n",
      "\n",
      "    :raises urllib3.exceptions.HeaderParsingError:\n",
      "        If parsing errors are found.\n",
      "    \"\"\"\n",
      "\n",
      "    # This will fail silently if we pass in the wrong kind of parameter.\n",
      "    # To make debugging easier add an explicit check.\n",
      "    if not isinstance(headers, httplib.HTTPMessage):\n",
      "        raise TypeError(\"expected httplib.Message, got {0}.\".format(type(headers)))\n",
      "\n",
      "    defects = getattr(headers, \"defects\", None)\n",
      "    get_payload = getattr(headers, \"get_payload\", None)\n",
      "\n",
      "    unparsed_data = None\n",
      "    if get_payload:\n",
      "        # get_payload is actually email.message.Message.get_payload;\n",
      "        # we're only interested in the result if it's not a multipart message\n",
      "        if not headers.is_multipart():\n",
      "            payload = get_payload()\n",
      "\n",
      "            if isinstance(payload, (bytes, str)):\n",
      "                unparsed_data = payload\n",
      "    if defects:\n",
      "        # httplib is assuming a response body is available\n",
      "        # when parsing headers even when httplib only sends\n",
      "        # header data to parse_headers() This results in\n",
      "        # defects on multipart responses in particular.\n",
      "        # See: https://github.com/urllib3/urllib3/issues/800\n",
      "\n",
      "        # So we ignore the following defects:\n",
      "        # - StartBoundaryNotFoundDefect:\n",
      "        #     The claimed start boundary was never found.\n",
      "        # - MultipartInvariantViolationDefect:\n",
      "        #     A message claimed to be a multipart but no subparts were found.\n",
      "        defects = [\n",
      "            defect\n",
      "            for defect in defects\n",
      "            if not isinstance(\n",
      "                defect, (StartBoundaryNotFoundDefect, MultipartInvariantViolationDefect)\n",
      "            )\n",
      "        ]\n",
      "\n",
      "    if defects or unparsed_data:\n",
      "        raise HeaderParsingError(defects=defects, unparsed_data=unparsed_data)\n",
      "\n",
      "================================================================================\n",
      "Function Name: connection_from_url\n",
      "Source Code:\n",
      "def connection_from_url(url, **kw):\n",
      "    \"\"\"\n",
      "    Given a url, return an :class:`.ConnectionPool` instance of its host.\n",
      "\n",
      "    This is a shortcut for not having to parse out the scheme, host, and port\n",
      "    of the url before creating an :class:`.ConnectionPool` instance.\n",
      "\n",
      "    :param url:\n",
      "        Absolute URL string that must include the scheme. Port is optional.\n",
      "\n",
      "    :param \\\\**kw:\n",
      "        Passes additional parameters to the constructor of the appropriate\n",
      "        :class:`.ConnectionPool`. Useful for specifying things like\n",
      "        timeout, maxsize, headers, etc.\n",
      "\n",
      "    Example::\n",
      "\n",
      "        >>> conn = connection_from_url('http://google.com/')\n",
      "        >>> r = conn.request('GET', '/')\n",
      "    \"\"\"\n",
      "    scheme, host, port = get_host(url)\n",
      "    port = port or port_by_scheme.get(scheme, 80)\n",
      "    if scheme == \"https\":\n",
      "        return HTTPSConnectionPool(host, port=port, **kw)\n",
      "    else:\n",
      "        return HTTPConnectionPool(host, port=port, **kw)\n",
      "\n",
      "================================================================================\n",
      "Function Name: connection_requires_http_tunnel\n",
      "Source Code:\n",
      "def connection_requires_http_tunnel(\n",
      "    proxy_url=None, proxy_config=None, destination_scheme=None\n",
      "):\n",
      "    \"\"\"\n",
      "    Returns True if the connection requires an HTTP CONNECT through the proxy.\n",
      "\n",
      "    :param URL proxy_url:\n",
      "        URL of the proxy.\n",
      "    :param ProxyConfig proxy_config:\n",
      "        Proxy configuration from poolmanager.py\n",
      "    :param str destination_scheme:\n",
      "        The scheme of the destination. (i.e https, http, etc)\n",
      "    \"\"\"\n",
      "    # If we're not using a proxy, no way to use a tunnel.\n",
      "    if proxy_url is None:\n",
      "        return False\n",
      "\n",
      "    # HTTP destinations never require tunneling, we always forward.\n",
      "    if destination_scheme == \"http\":\n",
      "        return False\n",
      "\n",
      "    # Support for forwarding with HTTPS proxies and HTTPS destinations.\n",
      "    if (\n",
      "        proxy_url.scheme == \"https\"\n",
      "        and proxy_config\n",
      "        and proxy_config.use_forwarding_for_https\n",
      "    ):\n",
      "        return False\n",
      "\n",
      "    # Otherwise always use a tunnel.\n",
      "    return True\n",
      "\n",
      "================================================================================\n",
      "Function Name: get_host\n",
      "Source Code:\n",
      "def get_host(url):\n",
      "    \"\"\"\n",
      "    Deprecated. Use :func:`parse_url` instead.\n",
      "    \"\"\"\n",
      "    p = parse_url(url)\n",
      "    return p.scheme or \"http\", p.hostname, p.port\n",
      "\n",
      "================================================================================\n",
      "Function Name: is_connection_dropped\n",
      "Source Code:\n",
      "def is_connection_dropped(conn):  # Platform-specific\n",
      "    \"\"\"\n",
      "    Returns True if the connection is dropped and should be closed.\n",
      "\n",
      "    :param conn:\n",
      "        :class:`http.client.HTTPConnection` object.\n",
      "\n",
      "    Note: For platforms like AppEngine, this will always return ``False`` to\n",
      "    let the platform handle connection recycling transparently for us.\n",
      "    \"\"\"\n",
      "    sock = getattr(conn, \"sock\", False)\n",
      "    if sock is False:  # Platform-specific: AppEngine\n",
      "        return False\n",
      "    if sock is None:  # Connection already closed (such as by httplib).\n",
      "        return True\n",
      "    try:\n",
      "        # Returns True if readable, which here means it's been dropped\n",
      "        return wait_for_read(sock, timeout=0.0)\n",
      "    except NoWayToWaitForSocketError:  # Platform-specific: AppEngine\n",
      "        return False\n",
      "\n",
      "================================================================================\n",
      "Function Name: normalize_host\n",
      "Source Code:\n",
      "def _normalize_host(host, scheme):\n",
      "    if host:\n",
      "        if isinstance(host, six.binary_type):\n",
      "            host = six.ensure_str(host)\n",
      "\n",
      "        if scheme in NORMALIZABLE_SCHEMES:\n",
      "            is_ipv6 = IPV6_ADDRZ_RE.match(host)\n",
      "            if is_ipv6:\n",
      "                # IPv6 hosts of the form 'a::b%zone' are encoded in a URL as\n",
      "                # such per RFC 6874: 'a::b%25zone'. Unquote the ZoneID\n",
      "                # separator as necessary to return a valid RFC 4007 scoped IP.\n",
      "                match = ZONE_ID_RE.search(host)\n",
      "                if match:\n",
      "                    start, end = match.span(1)\n",
      "                    zone_id = host[start:end]\n",
      "\n",
      "                    if zone_id.startswith(\"%25\") and zone_id != \"%25\":\n",
      "                        zone_id = zone_id[3:]\n",
      "                    else:\n",
      "                        zone_id = zone_id[1:]\n",
      "                    zone_id = \"%\" + _encode_invalid_chars(zone_id, UNRESERVED_CHARS)\n",
      "                    return host[:start].lower() + zone_id + host[end:]\n",
      "                else:\n",
      "                    return host.lower()\n",
      "            elif not IPV4_RE.match(host):\n",
      "                return six.ensure_str(\n",
      "                    b\".\".join([_idna_encode(label) for label in host.split(\".\")])\n",
      "                )\n",
      "    return host\n",
      "\n",
      "================================================================================\n",
      "Function Name: parse_url\n",
      "Source Code:\n",
      "def parse_url(url):\n",
      "    \"\"\"\n",
      "    Given a url, return a parsed :class:`.Url` namedtuple. Best-effort is\n",
      "    performed to parse incomplete urls. Fields not provided will be None.\n",
      "    This parser is RFC 3986 and RFC 6874 compliant.\n",
      "\n",
      "    The parser logic and helper functions are based heavily on\n",
      "    work done in the ``rfc3986`` module.\n",
      "\n",
      "    :param str url: URL to parse into a :class:`.Url` namedtuple.\n",
      "\n",
      "    Partly backwards-compatible with :mod:`urlparse`.\n",
      "\n",
      "    Example::\n",
      "\n",
      "        >>> parse_url('http://google.com/mail/')\n",
      "        Url(scheme='http', host='google.com', port=None, path='/mail/', ...)\n",
      "        >>> parse_url('google.com:80')\n",
      "        Url(scheme=None, host='google.com', port=80, path=None, ...)\n",
      "        >>> parse_url('/foo?bar')\n",
      "        Url(scheme=None, host=None, port=None, path='/foo', query='bar', ...)\n",
      "    \"\"\"\n",
      "    if not url:\n",
      "        # Empty\n",
      "        return Url()\n",
      "\n",
      "    source_url = url\n",
      "    if not SCHEME_RE.search(url):\n",
      "        url = \"//\" + url\n",
      "\n",
      "    try:\n",
      "        scheme, authority, path, query, fragment = URI_RE.match(url).groups()\n",
      "        normalize_uri = scheme is None or scheme.lower() in NORMALIZABLE_SCHEMES\n",
      "\n",
      "        if scheme:\n",
      "            scheme = scheme.lower()\n",
      "\n",
      "        if authority:\n",
      "            auth, _, host_port = authority.rpartition(\"@\")\n",
      "            auth = auth or None\n",
      "            host, port = _HOST_PORT_RE.match(host_port).groups()\n",
      "            if auth and normalize_uri:\n",
      "                auth = _encode_invalid_chars(auth, USERINFO_CHARS)\n",
      "            if port == \"\":\n",
      "                port = None\n",
      "        else:\n",
      "            auth, host, port = None, None, None\n",
      "\n",
      "        if port is not None:\n",
      "            port = int(port)\n",
      "            if not (0 <= port <= 65535):\n",
      "                raise LocationParseError(url)\n",
      "\n",
      "        host = _normalize_host(host, scheme)\n",
      "\n",
      "        if normalize_uri and path:\n",
      "            path = _remove_path_dot_segments(path)\n",
      "            path = _encode_invalid_chars(path, PATH_CHARS)\n",
      "        if normalize_uri and query:\n",
      "            query = _encode_invalid_chars(query, QUERY_CHARS)\n",
      "        if normalize_uri and fragment:\n",
      "            fragment = _encode_invalid_chars(fragment, FRAGMENT_CHARS)\n",
      "\n",
      "    except (ValueError, AttributeError):\n",
      "        return six.raise_from(LocationParseError(source_url), None)\n",
      "\n",
      "    # For the sake of backwards compatibility we put empty\n",
      "    # string values for path if there are any defined values\n",
      "    # beyond the path in the URL.\n",
      "    # TODO: Remove this when we break backwards compatibility.\n",
      "    if not path:\n",
      "        if query is not None or fragment is not None:\n",
      "            path = \"\"\n",
      "        else:\n",
      "            path = None\n",
      "\n",
      "    # Ensure that each part of the URL is a `str` for\n",
      "    # backwards compatibility.\n",
      "    if isinstance(url, six.text_type):\n",
      "        ensure_func = six.ensure_text\n",
      "    else:\n",
      "        ensure_func = six.ensure_str\n",
      "\n",
      "    def ensure_type(x):\n",
      "        return x if x is None else ensure_func(x)\n",
      "\n",
      "    return Url(\n",
      "        scheme=ensure_type(scheme),\n",
      "        auth=ensure_type(auth),\n",
      "        host=ensure_type(host),\n",
      "        port=port,\n",
      "        path=ensure_type(path),\n",
      "        query=ensure_type(query),\n",
      "        fragment=ensure_type(fragment),\n",
      "    )\n",
      "\n",
      "================================================================================\n",
      "Function Name: set_file_position\n",
      "Source Code:\n",
      "def set_file_position(body, pos):\n",
      "    \"\"\"\n",
      "    If a position is provided, move file to that point.\n",
      "    Otherwise, we'll attempt to record a position for future use.\n",
      "    \"\"\"\n",
      "    if pos is not None:\n",
      "        rewind_body(body, pos)\n",
      "    elif getattr(body, \"tell\", None) is not None:\n",
      "        try:\n",
      "            pos = body.tell()\n",
      "        except (IOError, OSError):\n",
      "            # This differentiates from None, allowing us to catch\n",
      "            # a failed `tell()` later when trying to rewind the body.\n",
      "            pos = _FAILEDTELL\n",
      "\n",
      "    return pos\n",
      "\n",
      "================================================================================\n",
      "Function Name: _replace_multiple\n",
      "Source Code:\n",
      "def _replace_multiple(value, needles_and_replacements):\n",
      "    def replacer(match):\n",
      "        return needles_and_replacements[match.group(0)]\n",
      "\n",
      "    pattern = re.compile(\n",
      "        r\"|\".join([re.escape(needle) for needle in needles_and_replacements.keys()])\n",
      "    )\n",
      "\n",
      "    result = pattern.sub(replacer, value)\n",
      "\n",
      "    return result\n",
      "\n",
      "================================================================================\n",
      "Function Name: format_header_param\n",
      "Source Code:\n",
      "def format_header_param_html5(name, value):\n",
      "    \"\"\"\n",
      "    Helper function to format and quote a single header parameter using the\n",
      "    HTML5 strategy.\n",
      "\n",
      "    Particularly useful for header parameters which might contain\n",
      "    non-ASCII values, like file names. This follows the `HTML5 Working Draft\n",
      "    Section 4.10.22.7`_ and matches the behavior of curl and modern browsers.\n",
      "\n",
      "    .. _HTML5 Working Draft Section 4.10.22.7:\n",
      "        https://w3c.github.io/html/sec-forms.html#multipart-form-data\n",
      "\n",
      "    :param name:\n",
      "        The name of the parameter, a string expected to be ASCII only.\n",
      "    :param value:\n",
      "        The value of the parameter, provided as ``bytes`` or `str``.\n",
      "    :ret:\n",
      "        A unicode string, stripped of troublesome characters.\n",
      "    \"\"\"\n",
      "    if isinstance(value, six.binary_type):\n",
      "        value = value.decode(\"utf-8\")\n",
      "\n",
      "    value = _replace_multiple(value, _HTML5_REPLACEMENTS)\n",
      "\n",
      "    return u'%s=\"%s\"' % (name, value)\n",
      "\n",
      "================================================================================\n",
      "Function Name: format_header_param_html5\n",
      "Source Code:\n",
      "def format_header_param_html5(name, value):\n",
      "    \"\"\"\n",
      "    Helper function to format and quote a single header parameter using the\n",
      "    HTML5 strategy.\n",
      "\n",
      "    Particularly useful for header parameters which might contain\n",
      "    non-ASCII values, like file names. This follows the `HTML5 Working Draft\n",
      "    Section 4.10.22.7`_ and matches the behavior of curl and modern browsers.\n",
      "\n",
      "    .. _HTML5 Working Draft Section 4.10.22.7:\n",
      "        https://w3c.github.io/html/sec-forms.html#multipart-form-data\n",
      "\n",
      "    :param name:\n",
      "        The name of the parameter, a string expected to be ASCII only.\n",
      "    :param value:\n",
      "        The value of the parameter, provided as ``bytes`` or `str``.\n",
      "    :ret:\n",
      "        A unicode string, stripped of troublesome characters.\n",
      "    \"\"\"\n",
      "    if isinstance(value, six.binary_type):\n",
      "        value = value.decode(\"utf-8\")\n",
      "\n",
      "    value = _replace_multiple(value, _HTML5_REPLACEMENTS)\n",
      "\n",
      "    return u'%s=\"%s\"' % (name, value)\n",
      "\n",
      "================================================================================\n",
      "Function Name: format_header_param_rfc2231\n",
      "Source Code:\n",
      "def format_header_param_rfc2231(name, value):\n",
      "    \"\"\"\n",
      "    Helper function to format and quote a single header parameter using the\n",
      "    strategy defined in RFC 2231.\n",
      "\n",
      "    Particularly useful for header parameters which might contain\n",
      "    non-ASCII values, like file names. This follows\n",
      "    `RFC 2388 Section 4.4 <https://tools.ietf.org/html/rfc2388#section-4.4>`_.\n",
      "\n",
      "    :param name:\n",
      "        The name of the parameter, a string expected to be ASCII only.\n",
      "    :param value:\n",
      "        The value of the parameter, provided as ``bytes`` or `str``.\n",
      "    :ret:\n",
      "        An RFC-2231-formatted unicode string.\n",
      "    \"\"\"\n",
      "    if isinstance(value, six.binary_type):\n",
      "        value = value.decode(\"utf-8\")\n",
      "\n",
      "    if not any(ch in value for ch in '\"\\\\\\r\\n'):\n",
      "        result = u'%s=\"%s\"' % (name, value)\n",
      "        try:\n",
      "            result.encode(\"ascii\")\n",
      "        except (UnicodeEncodeError, UnicodeDecodeError):\n",
      "            pass\n",
      "        else:\n",
      "            return result\n",
      "\n",
      "    if six.PY2:  # Python 2:\n",
      "        value = value.encode(\"utf-8\")\n",
      "\n",
      "    # encode_rfc2231 accepts an encoded string and returns an ascii-encoded\n",
      "    # string in Python 2 but accepts and returns unicode strings in Python 3\n",
      "    value = email.utils.encode_rfc2231(value, \"utf-8\")\n",
      "    value = \"%s*=%s\" % (name, value)\n",
      "\n",
      "    if six.PY2:  # Python 2:\n",
      "        value = value.decode(\"utf-8\")\n",
      "\n",
      "    return value\n",
      "\n",
      "================================================================================\n",
      "Function Name: guess_content_type\n",
      "Source Code:\n",
      "def guess_content_type(filename, default=\"application/octet-stream\"):\n",
      "    \"\"\"\n",
      "    Guess the \"Content-Type\" of a file.\n",
      "\n",
      "    :param filename:\n",
      "        The filename to guess the \"Content-Type\" of using :mod:`mimetypes`.\n",
      "    :param default:\n",
      "        If no \"Content-Type\" can be guessed, default to `default`.\n",
      "    \"\"\"\n",
      "    if filename:\n",
      "        return mimetypes.guess_type(filename)[0] or default\n",
      "    return default\n",
      "\n",
      "================================================================================\n",
      "Function Name: b\n",
      "Source Code:\n",
      "    def b(s):\n",
      "        return s.encode(\"latin-1\")\n",
      "\n",
      "================================================================================\n",
      "Function Name: choose_boundary\n",
      "Source Code:\n",
      "def choose_boundary():\n",
      "    \"\"\"\n",
      "    Our embarrassingly-simple replacement for mimetools.choose_boundary.\n",
      "    \"\"\"\n",
      "    boundary = binascii.hexlify(os.urandom(16))\n",
      "    if not six.PY2:\n",
      "        boundary = boundary.decode(\"ascii\")\n",
      "    return boundary\n",
      "\n",
      "================================================================================\n",
      "Function Name: encode_multipart_formdata\n",
      "Source Code:\n",
      "def encode_multipart_formdata(fields, boundary=None):\n",
      "    \"\"\"\n",
      "    Encode a dictionary of ``fields`` using the multipart/form-data MIME format.\n",
      "\n",
      "    :param fields:\n",
      "        Dictionary of fields or list of (key, :class:`~urllib3.fields.RequestField`).\n",
      "\n",
      "    :param boundary:\n",
      "        If not specified, then a random boundary will be generated using\n",
      "        :func:`urllib3.filepost.choose_boundary`.\n",
      "    \"\"\"\n",
      "    body = BytesIO()\n",
      "    if boundary is None:\n",
      "        boundary = choose_boundary()\n",
      "\n",
      "    for field in iter_field_objects(fields):\n",
      "        body.write(b(\"--%s\\r\\n\" % (boundary)))\n",
      "\n",
      "        writer(body).write(field.render_headers())\n",
      "        data = field.data\n",
      "\n",
      "        if isinstance(data, int):\n",
      "            data = str(data)  # Backwards compatibility\n",
      "\n",
      "        if isinstance(data, six.text_type):\n",
      "            writer(body).write(data)\n",
      "        else:\n",
      "            body.write(data)\n",
      "\n",
      "        body.write(b\"\\r\\n\")\n",
      "\n",
      "    body.write(b(\"--%s--\\r\\n\" % (boundary)))\n",
      "\n",
      "    content_type = str(\"multipart/form-data; boundary=%s\" % boundary)\n",
      "\n",
      "    return body.getvalue(), content_type\n",
      "\n",
      "================================================================================\n",
      "Function Name: iter_field_objects\n",
      "Source Code:\n",
      "def iter_field_objects(fields):\n",
      "    \"\"\"\n",
      "    Iterate over fields.\n",
      "\n",
      "    Supports list of (k, v) tuples and dicts, and lists of\n",
      "    :class:`~urllib3.fields.RequestField`.\n",
      "\n",
      "    \"\"\"\n",
      "    if isinstance(fields, dict):\n",
      "        i = six.iteritems(fields)\n",
      "    else:\n",
      "        i = iter(fields)\n",
      "\n",
      "    for field in i:\n",
      "        if isinstance(field, RequestField):\n",
      "            yield field\n",
      "        else:\n",
      "            yield RequestField.from_tuples(*field)\n",
      "\n",
      "================================================================================\n",
      "Function Name: iter_fields\n",
      "Source Code:\n",
      "def iter_fields(fields):\n",
      "    \"\"\"\n",
      "    .. deprecated:: 1.6\n",
      "\n",
      "    Iterate over fields.\n",
      "\n",
      "    The addition of :class:`~urllib3.fields.RequestField` makes this function\n",
      "    obsolete. Instead, use :func:`iter_field_objects`, which returns\n",
      "    :class:`~urllib3.fields.RequestField` objects.\n",
      "\n",
      "    Supports list of (k, v) tuples and dicts.\n",
      "    \"\"\"\n",
      "    if isinstance(fields, dict):\n",
      "        return ((k, v) for k, v in six.iteritems(fields))\n",
      "\n",
      "    return ((k, v) for k, v in fields)\n",
      "\n",
      "================================================================================\n",
      "Function Name: _default_key_normalizer\n",
      "Source Code:\n",
      "def _default_key_normalizer(key_class, request_context):\n",
      "    \"\"\"\n",
      "    Create a pool key out of a request context dictionary.\n",
      "\n",
      "    According to RFC 3986, both the scheme and host are case-insensitive.\n",
      "    Therefore, this function normalizes both before constructing the pool\n",
      "    key for an HTTPS request. If you wish to change this behaviour, provide\n",
      "    alternate callables to ``key_fn_by_scheme``.\n",
      "\n",
      "    :param key_class:\n",
      "        The class to use when constructing the key. This should be a namedtuple\n",
      "        with the ``scheme`` and ``host`` keys at a minimum.\n",
      "    :type  key_class: namedtuple\n",
      "    :param request_context:\n",
      "        A dictionary-like object that contain the context for a request.\n",
      "    :type  request_context: dict\n",
      "\n",
      "    :return: A namedtuple that can be used as a connection pool key.\n",
      "    :rtype:  PoolKey\n",
      "    \"\"\"\n",
      "    # Since we mutate the dictionary, make a copy first\n",
      "    context = request_context.copy()\n",
      "    context[\"scheme\"] = context[\"scheme\"].lower()\n",
      "    context[\"host\"] = context[\"host\"].lower()\n",
      "\n",
      "    # These are both dictionaries and need to be transformed into frozensets\n",
      "    for key in (\"headers\", \"_proxy_headers\", \"_socks_options\"):\n",
      "        if key in context and context[key] is not None:\n",
      "            context[key] = frozenset(context[key].items())\n",
      "\n",
      "    # The socket_options key may be a list and needs to be transformed into a\n",
      "    # tuple.\n",
      "    socket_opts = context.get(\"socket_options\")\n",
      "    if socket_opts is not None:\n",
      "        context[\"socket_options\"] = tuple(socket_opts)\n",
      "\n",
      "    # Map the kwargs to the names in the namedtuple - this is necessary since\n",
      "    # namedtuples can't have fields starting with '_'.\n",
      "    for key in list(context.keys()):\n",
      "        context[\"key_\" + key] = context.pop(key)\n",
      "\n",
      "    # Default to ``None`` for keys missing from the context\n",
      "    for field in key_class._fields:\n",
      "        if field not in context:\n",
      "            context[field] = None\n",
      "\n",
      "    return key_class(**context)\n",
      "\n",
      "================================================================================\n",
      "Function Name: proxy_from_url\n",
      "Source Code:\n",
      "def proxy_from_url(url, **kw):\n",
      "    return ProxyManager(proxy_url=url, **kw)\n",
      "\n",
      "================================================================================\n",
      "Function Name: urljoin\n",
      "Source Code:\n",
      "def urljoin(base, url, allow_fragments=True):\n",
      "    \"\"\"Join a base URL and a possibly relative URL to form an absolute\n",
      "    interpretation of the latter.\"\"\"\n",
      "    if not base:\n",
      "        return url\n",
      "    if not url:\n",
      "        return base\n",
      "\n",
      "    base, url, _coerce_result = _coerce_args(base, url)\n",
      "    bscheme, bnetloc, bpath, bparams, bquery, bfragment = \\\n",
      "            urlparse(base, '', allow_fragments)\n",
      "    scheme, netloc, path, params, query, fragment = \\\n",
      "            urlparse(url, bscheme, allow_fragments)\n",
      "\n",
      "    if scheme != bscheme or scheme not in uses_relative:\n",
      "        return _coerce_result(url)\n",
      "    if scheme in uses_netloc:\n",
      "        if netloc:\n",
      "            return _coerce_result(urlunparse((scheme, netloc, path,\n",
      "                                              params, query, fragment)))\n",
      "        netloc = bnetloc\n",
      "\n",
      "    if not path and not params:\n",
      "        path = bpath\n",
      "        params = bparams\n",
      "        if not query:\n",
      "            query = bquery\n",
      "        return _coerce_result(urlunparse((scheme, netloc, path,\n",
      "                                          params, query, fragment)))\n",
      "\n",
      "    base_parts = bpath.split('/')\n",
      "    if base_parts[-1] != '':\n",
      "        # the last item is not a directory, so will not be taken into account\n",
      "        # in resolving the relative path\n",
      "        del base_parts[-1]\n",
      "\n",
      "    # for rfc3986, ignore all base path should the first character be root.\n",
      "    if path[:1] == '/':\n",
      "        segments = path.split('/')\n",
      "    else:\n",
      "        segments = base_parts + path.split('/')\n",
      "        # filter out elements that would cause redundant slashes on re-joining\n",
      "        # the resolved_path\n",
      "        segments[1:-1] = filter(None, segments[1:-1])\n",
      "\n",
      "    resolved_path = []\n",
      "\n",
      "    for seg in segments:\n",
      "        if seg == '..':\n",
      "            try:\n",
      "                resolved_path.pop()\n",
      "            except IndexError:\n",
      "                # ignore any .. segments that would otherwise cause an IndexError\n",
      "                # when popped from resolved_path if resolving for rfc3986\n",
      "                pass\n",
      "        elif seg == '.':\n",
      "            continue\n",
      "        else:\n",
      "            resolved_path.append(seg)\n",
      "\n",
      "    if segments[-1] in ('.', '..'):\n",
      "        # do some post-processing here. if the last segment was a relative dir,\n",
      "        # then we need to append the trailing '/'\n",
      "        resolved_path.append('')\n",
      "\n",
      "    return _coerce_result(urlunparse((scheme, netloc, '/'.join(\n",
      "        resolved_path) or '/', params, query, fragment)))\n",
      "\n",
      "================================================================================\n",
      "Function Name: urlencode\n",
      "Source Code:\n",
      "def urlencode(query, doseq=False, safe='', encoding=None, errors=None,\n",
      "              quote_via=quote_plus):\n",
      "    \"\"\"Encode a dict or sequence of two-element tuples into a URL query string.\n",
      "\n",
      "    If any values in the query arg are sequences and doseq is true, each\n",
      "    sequence element is converted to a separate parameter.\n",
      "\n",
      "    If the query arg is a sequence of two-element tuples, the order of the\n",
      "    parameters in the output will match the order of parameters in the\n",
      "    input.\n",
      "\n",
      "    The components of a query arg may each be either a string or a bytes type.\n",
      "\n",
      "    The safe, encoding, and errors parameters are passed down to the function\n",
      "    specified by quote_via (encoding and errors only if a component is a str).\n",
      "    \"\"\"\n",
      "\n",
      "    if hasattr(query, \"items\"):\n",
      "        query = query.items()\n",
      "    else:\n",
      "        # It's a bother at times that strings and string-like objects are\n",
      "        # sequences.\n",
      "        try:\n",
      "            # non-sequence items should not work with len()\n",
      "            # non-empty strings will fail this\n",
      "            if len(query) and not isinstance(query[0], tuple):\n",
      "                raise TypeError\n",
      "            # Zero-length sequences of all types will get here and succeed,\n",
      "            # but that's a minor nit.  Since the original implementation\n",
      "            # allowed empty dicts that type of behavior probably should be\n",
      "            # preserved for consistency\n",
      "        except TypeError:\n",
      "            ty, va, tb = sys.exc_info()\n",
      "            raise TypeError(\"not a valid non-string sequence \"\n",
      "                            \"or mapping object\").with_traceback(tb)\n",
      "\n",
      "    l = []\n",
      "    if not doseq:\n",
      "        for k, v in query:\n",
      "            if isinstance(k, bytes):\n",
      "                k = quote_via(k, safe)\n",
      "            else:\n",
      "                k = quote_via(str(k), safe, encoding, errors)\n",
      "\n",
      "            if isinstance(v, bytes):\n",
      "                v = quote_via(v, safe)\n",
      "            else:\n",
      "                v = quote_via(str(v), safe, encoding, errors)\n",
      "            l.append(k + '=' + v)\n",
      "    else:\n",
      "        for k, v in query:\n",
      "            if isinstance(k, bytes):\n",
      "                k = quote_via(k, safe)\n",
      "            else:\n",
      "                k = quote_via(str(k), safe, encoding, errors)\n",
      "\n",
      "            if isinstance(v, bytes):\n",
      "                v = quote_via(v, safe)\n",
      "                l.append(k + '=' + v)\n",
      "            elif isinstance(v, str):\n",
      "                v = quote_via(v, safe, encoding, errors)\n",
      "                l.append(k + '=' + v)\n",
      "            else:\n",
      "                try:\n",
      "                    # Is this a sufficient test for sequence-ness?\n",
      "                    x = len(v)\n",
      "                except TypeError:\n",
      "                    # not a sequence\n",
      "                    v = quote_via(str(v), safe, encoding, errors)\n",
      "                    l.append(k + '=' + v)\n",
      "                else:\n",
      "                    # loop over the sequence\n",
      "                    for elt in v:\n",
      "                        if isinstance(elt, bytes):\n",
      "                            elt = quote_via(elt, safe)\n",
      "                        else:\n",
      "                            elt = quote_via(str(elt), safe, encoding, errors)\n",
      "                        l.append(k + '=' + elt)\n",
      "    return '&'.join(l)\n",
      "\n",
      "================================================================================\n",
      "Function Name: _get_decoder\n",
      "Source Code:\n",
      "def _get_decoder(mode):\n",
      "    if \",\" in mode:\n",
      "        return MultiDecoder(mode)\n",
      "\n",
      "    if mode == \"gzip\":\n",
      "        return GzipDecoder()\n",
      "\n",
      "    if brotli is not None and mode == \"br\":\n",
      "        return BrotliDecoder()\n",
      "\n",
      "    return DeflateDecoder()\n",
      "\n",
      "================================================================================\n",
      "Function Name: contextmanager\n",
      "Source Code:\n",
      "def contextmanager(func):\n",
      "    \"\"\"@contextmanager decorator.\n",
      "\n",
      "    Typical usage:\n",
      "\n",
      "        @contextmanager\n",
      "        def some_generator(<arguments>):\n",
      "            <setup>\n",
      "            try:\n",
      "                yield <value>\n",
      "            finally:\n",
      "                <cleanup>\n",
      "\n",
      "    This makes this:\n",
      "\n",
      "        with some_generator(<arguments>) as <variable>:\n",
      "            <body>\n",
      "\n",
      "    equivalent to this:\n",
      "\n",
      "        <setup>\n",
      "        try:\n",
      "            <variable> = <value>\n",
      "            <body>\n",
      "        finally:\n",
      "            <cleanup>\n",
      "    \"\"\"\n",
      "    @wraps(func)\n",
      "    def helper(*args, **kwds):\n",
      "        return _GeneratorContextManager(func, args, kwds)\n",
      "    return helper\n",
      "\n",
      "================================================================================\n",
      "Function Name: is_fp_closed\n",
      "Source Code:\n",
      "def is_fp_closed(obj):\n",
      "    \"\"\"\n",
      "    Checks whether a given file-like object is closed.\n",
      "\n",
      "    :param obj:\n",
      "        The file-like object to check.\n",
      "    \"\"\"\n",
      "\n",
      "    try:\n",
      "        # Check `isclosed()` first, in case Python3 doesn't set `closed`.\n",
      "        # GH Issue #928\n",
      "        return obj.isclosed()\n",
      "    except AttributeError:\n",
      "        pass\n",
      "\n",
      "    try:\n",
      "        # Check via the official file-like-object way.\n",
      "        return obj.closed\n",
      "    except AttributeError:\n",
      "        pass\n",
      "\n",
      "    try:\n",
      "        # Check if the object is a container for another file-like object that\n",
      "        # gets released on exhaustion (e.g. HTTPResponse).\n",
      "        return obj.fp is None\n",
      "    except AttributeError:\n",
      "        pass\n",
      "\n",
      "    raise ValueError(\"Unable to determine whether fp is closed.\")\n",
      "\n",
      "================================================================================\n",
      "Function Name: is_response_to_head\n",
      "Source Code:\n",
      "def is_response_to_head(response):\n",
      "    \"\"\"\n",
      "    Checks whether the request of a response has been a HEAD-request.\n",
      "    Handles the quirks of AppEngine.\n",
      "\n",
      "    :param http.client.HTTPResponse response:\n",
      "        Response to check if the originating request\n",
      "        used 'HEAD' as a method.\n",
      "    \"\"\"\n",
      "    # FIXME: Can we do this somehow without accessing private httplib _method?\n",
      "    method = response._method\n",
      "    if isinstance(method, int):  # Platform-specific: Appengine\n",
      "        return method == 3\n",
      "    return method.upper() == \"HEAD\"\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "#get all functions and source code from a library\n",
    "import inspect\n",
    "import importlib\n",
    "import pkgutil\n",
    "import sys\n",
    "\n",
    "def get_functions_and_code_from_library(library_name):\n",
    "    funcs = {}\n",
    "    library = importlib.import_module(library_name)\n",
    "\n",
    "    # Iterate through all the modules within the library\n",
    "    for _, name, is_pkg in pkgutil.walk_packages(library.__path__):\n",
    "        if is_pkg:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            module = importlib.import_module(f\"{library_name}.{name}\")\n",
    "\n",
    "            for func_name, obj in inspect.getmembers(module):\n",
    "                if inspect.isfunction(obj):\n",
    "                    funcs.update({func_name: inspect.getsource(obj)})\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading module {name}: {e}\")\n",
    "\n",
    "    return funcs\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    library_name = \"urllib3\"  # Replace this with the library you want to analyze\n",
    "    functions = get_functions_and_code_from_library(library_name)\n",
    "\n",
    "    # Print function names and their source code\n",
    "    for func_name, source_code in functions.items():\n",
    "        print(f\"Function Name: {func_name}\")\n",
    "        print(\"Source Code:\")\n",
    "        print(source_code)\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "priority_funcs = 'create_urllib3_context', 'ssl_wrap_socket','match_hostname', 'parse_url'\n",
    "# find priority functions from functions first, then move on to other functions\n",
    "# if priority functions are not found, then move on to other functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create_urllib3_context - C\n",
      "ssl_wrap_socket - C\n",
      "match_hostname - C\n",
      "parse_url - D\n"
     ]
    }
   ],
   "source": [
    "# create and parse radon CC metrics to create list of priority functions\n",
    "data = \"\"\"\n",
    "    F 95:0 _default_key_normalizer - B\n",
    "    F 623:0 proxy_from_url - A\n",
    "    F 43:0 ensure_can_construct_http_header_dict - B\n",
    "    F 701:0 _ssl_wrap_socket_and_match_hostname - D\n",
    "    F 845:0 _wrap_proxy_error - A\n",
    "    F 819:0 _match_hostname - A\n",
    "    F 884:0 _url_from_connection - A\n",
    "    F 869:0 _get_default_user_agent - A\n",
    "    F 1106:0 connection_from_url - A\n",
    "    F 1145:0 _normalize_host - A\n",
    "    F 1170:0 _close_pool_connections - A\n",
    "    F 1136:0 _normalize_host - A\n",
    "    F 1141:0 _normalize_host - A\n",
    "    F 1163:0 _url_from_pool - A\n",
    "    F 202:0 _get_decoder - B\n",
    "    F 87:0 add_stderr_logger - A\n",
    "    F 120:0 disable_warnings - A\n",
    "    F 130:0 request - A\n",
    "    F 51:0 encode_multipart_formdata - A\n",
    "    F 29:0 iter_field_objects - A\n",
    "    F 22:0 choose_boundary - A\n",
    "    F 31:0 format_header_param_rfc2231 - B\n",
    "    F 15:0 guess_content_type - A\n",
    "    F 79:0 format_multipart_header_param - A\n",
    "    F 117:0 format_header_param_html5 - A\n",
    "    F 135:0 format_header_param - A\n",
    "    F 193:0 _read_callback - C\n",
    "    F 250:0 _write_callback - C\n",
    "    F 173:0 inject_into_urllib3 - A\n",
    "    F 183:0 extract_from_urllib3 - A\n",
    "    F 729:0 makefile - A\n",
    "    F 235:0 get_subj_alt_name - B\n",
    "    F 168:0 _validate_dependencies_met - A\n",
    "    F 194:0 _dnsname_to_stdlib - A\n",
    "    F 148:0 inject_into_urllib3 - A\n",
    "    F 159:0 extract_from_urllib3 - A\n",
    "    F 549:0 _verify_callback - A\n",
    "    F 168:0 _cert_array_from_pem - B\n",
    "    F 322:0 _load_client_cert_chain - B\n",
    "    F 89:0 _create_cfstring_array - B\n",
    "    F 145:0 _assert_no_error - A\n",
    "    F 265:0 _load_items_from_file - A\n",
    "    F 120:0 _cf_string_to_unicode - A\n",
    "    F 51:0 _cf_dictionary_from_tuples - A\n",
    "    F 41:0 _cf_data_from_bytes - A\n",
    "    F 75:0 _cfstr - A\n",
    "    F 214:0 _is_cert - A\n",
    "    F 222:0 _is_identity - A\n",
    "    F 230:0 _temporary_keychain - A\n",
    "    F 406:0 _build_tls_unknown_ca_alert - A\n",
    "    F 65:0 load_cdll - A\n",
    "    F 33:0 select_wait_for_socket - B\n",
    "    F 57:0 poll_wait_for_socket - A\n",
    "    F 82:0 _have_working_poll - A\n",
    "    F 95:0 wait_for_socket - A\n",
    "    F 113:0 wait_for_read - A\n",
    "    F 120:0 wait_for_write - A\n",
    "    F 27:0 create_connection - B\n",
    "    F 114:0 _has_ipv6 - A\n",
    "    F 93:0 _set_socket_options - A\n",
    "    F 103:0 allowed_gai_family - A\n",
    "    F 15:0 is_connection_dropped - A\n",
    "    F 55:0 make_headers - B\n",
    "    F 189:0 body_to_chunks - B\n",
    "    F 154:0 rewind_body - A\n",
    "    F 134:0 set_file_position - A\n",
    "    F 11:0 connection_requires_http_tunnel - B\n",
    "    F 40:0 assert_header_parsing - B\n",
    "    F 9:0 is_fp_closed - A\n",
    "    F 91:0 is_response_to_head - A\n",
    "    F 7:0 to_bytes - B\n",
    "    F 19:0 to_str - B\n",
    "    F 31:0 reraise - A\n",
    "    F 369:0 parse_url - D\n",
    "    F 263:0 _remove_path_dot_segments - B\n",
    "    F 303:0 _normalize_host - B\n",
    "    F 227:0 _encode_invalid_chars - B\n",
    "    F 332:0 _idna_encode - A\n",
    "    F 351:0 _encode_target - A\n",
    "    F 214:0 _encode_invalid_chars - A\n",
    "    F 221:0 _encode_invalid_chars - A\n",
    "    F 294:0 _normalize_host - A\n",
    "    F 299:0 _normalize_host - A\n",
    "    F 208:0 create_urllib3_context - C\n",
    "    F 388:0 ssl_wrap_socket - C\n",
    "    F 28:0 _is_bpo_43522_fixed - B\n",
    "    F 139:0 assert_fingerprint - A\n",
    "    F 169:0 resolve_cert_reqs - A\n",
    "    F 192:0 resolve_ssl_version - A\n",
    "    F 463:0 is_ipaddress - A\n",
    "    F 476:0 _is_key_file_encrypted - A\n",
    "    F 487:0 _ssl_wrap_socket_impl - A\n",
    "    F 57:0 _is_has_never_check_common_name_reliable - A\n",
    "    F 351:0 ssl_wrap_socket - A\n",
    "    F 370:0 ssl_wrap_socket - A\n",
    "    F 95:0 match_hostname - C\n",
    "    F 24:0 _dnsname_match - B\n",
    "    F 80:0 _ipaddress_match - A\n",
    "\"\"\"\n",
    "\n",
    "def parse_function_data(data):\n",
    "    functions = []\n",
    "\n",
    "    for line in data.strip().split('\\n'):\n",
    "        parts = line.split()\n",
    "        function_name = parts[2]\n",
    "\n",
    "        if not function_name.startswith('_'):\n",
    "            score = parts[-1]\n",
    "            functions.append((function_name, score))\n",
    "\n",
    "    return functions\n",
    "\n",
    "def arrange_by_score(functions):\n",
    "    return sorted(functions, key=lambda x: x[1])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # radon cc src/ | grep -E '^\\s*F\\s+' > functions.txt\n",
    "    functions = parse_function_data(data)\n",
    "    arranged_functions = arrange_by_score(functions)\n",
    "\n",
    "    for function_name, score in arranged_functions:\n",
    "        # if score is not 'A' or 'B'\n",
    "        if score not in ('A', 'B'):\n",
    "            print(f\"{function_name} - {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "libs1 = {\n",
    "    'sqlalchemy': 'https://github.com/sqlalchemy/sqlalchemy',\n",
    "    'pillow': 'https://github.com/python-pillow/Pillow',\n",
    "    'babel': 'https://github.com/python-babel/babel',\n",
    "    'pyyaml': 'https://github.com/yaml/pyyaml',\n",
    "    'cryptography': {\n",
    "        'github': 'https://github.com/pyca/cryptography',\n",
    "        'docs': 'https://cryptography.io/en/latest/'\n",
    "    }\n",
    "}\n",
    "\n",
    "libs2 = {\n",
    "    'botocore': 'https://github.com/boto/botocore',\n",
    "    'boto3': 'https://github.com/boto/boto3',\n",
    "    'rq': 'https://github.com/rq/rq',\n",
    "    'pip': 'https://github.com/pypa/pip',\n",
    "    'grpc': {\n",
    "        'github': 'https://github.com/grpc/grpc',\n",
    "        'docs': 'https://grpc.github.io/grpc/python/'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    repo_path = \"github_repos\"\n",
    "    sqlitedb = \"langfuzz.db\"\n",
    "    http_libs = {\n",
    "     'urllib3': {\n",
    "    'github': 'https://github.com/urllib3/urllib3',\n",
    "    'docs': 'https://urllib3.readthedocs.io/en/stable/'\n",
    "    }}\n",
    "    utils = {\n",
    "    'oss-fuzz': {\n",
    "\t 'github': 'https://github.com/google/oss-fuzz'\n",
    "\t }}\n",
    "    libs = [http_libs, utils]\n",
    "\n",
    "    langfuzz_recon = LangFuzzRecon(sqlitedb, repo_path)\n",
    "    langfuzz_recon.download_github_repos(libs)\n",
    "    fuzz_files = langfuzz_recon.get_fuzz_files(http_libs)\n",
    "    print(fuzz_files)\n",
    "    langfuzz_recon.save_recon_data(http_libs, fuzz_files, 'python')\n",
    "\n",
    "    for library_name, lib_data in http_libs.items():\n",
    "        functions = langfuzz_recon.get_functions_and_code_from_library(library_name)\n",
    "        #print(functions)\n",
    "\n",
    "\n",
    "    #get functions with high cyclomatic complexity\n",
    "    priority_radon_funcs = langfuzz_recon.radon_metrics('urllib3')\n",
    "    print(priority_radon_funcs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
